{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed5f1ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CY2\\miniconda3\\envs\\DS\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import optuna\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e245060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ í´ë” ê°œìˆ˜: 8\n",
      "ì²« ë²ˆì§¸ í´ë” íŒŒì¼ ëª©ë¡ ì˜ˆì‹œ: ['201807_test_íšŒì›ì •ë³´.parquet', '201808_test_íšŒì›ì •ë³´.parquet', '201809_test_íšŒì›ì •ë³´.parquet', '201810_test_íšŒì›ì •ë³´.parquet', '201811_test_íšŒì›ì •ë³´.parquet', '201812_test_íšŒì›ì •ë³´.parquet']\n",
      "7ì›” ë°ì´í„° ë³‘í•© ì‹œì‘...\n",
      "âœ… 7ì›” ë³‘í•© ì™„ë£Œ! í¬ê¸°: (100000, 857)\n",
      "ğŸ’¾ credit_test_month_7.parquet ì €ì¥ ì™„ë£Œ.\n",
      "\n",
      "8ì›” ë°ì´í„° ë³‘í•© ì‹œì‘...\n",
      "âœ… 8ì›” ë³‘í•© ì™„ë£Œ! í¬ê¸°: (100000, 857)\n",
      "ğŸ’¾ credit_test_month_8.parquet ì €ì¥ ì™„ë£Œ.\n",
      "\n",
      "9ì›” ë°ì´í„° ë³‘í•© ì‹œì‘...\n",
      "âœ… 9ì›” ë³‘í•© ì™„ë£Œ! í¬ê¸°: (100000, 857)\n",
      "ğŸ’¾ credit_test_month_9.parquet ì €ì¥ ì™„ë£Œ.\n",
      "\n",
      "10ì›” ë°ì´í„° ë³‘í•© ì‹œì‘...\n",
      "âœ… 10ì›” ë³‘í•© ì™„ë£Œ! í¬ê¸°: (100000, 857)\n",
      "ğŸ’¾ credit_test_month_10.parquet ì €ì¥ ì™„ë£Œ.\n",
      "\n",
      "11ì›” ë°ì´í„° ë³‘í•© ì‹œì‘...\n",
      "âœ… 11ì›” ë³‘í•© ì™„ë£Œ! í¬ê¸°: (100000, 857)\n",
      "ğŸ’¾ credit_test_month_11.parquet ì €ì¥ ì™„ë£Œ.\n",
      "\n",
      "12ì›” ë°ì´í„° ë³‘í•© ì‹œì‘...\n",
      "âœ… 12ì›” ë³‘í•© ì™„ë£Œ! í¬ê¸°: (100000, 857)\n",
      "ğŸ’¾ credit_test_month_12.parquet ì €ì¥ ì™„ë£Œ.\n",
      "\n",
      "ğŸ‰ ëª¨ë“  Test ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "# ==========================================\n",
    "# 1. ê²½ë¡œ ì„¤ì • (Train -> Testë¡œ ë³€ê²½)\n",
    "# ==========================================\n",
    "# ê° í´ë”ëª… ë”•ì…”ë„ˆë¦¬ (ë™ì¼í•¨)\n",
    "folder_name = {1:\"1.íšŒì›ì •ë³´\", 2:\"2.ì‹ ìš©ì •ë³´\", 3:\"3.ìŠ¹ì¸ë§¤ì¶œì •ë³´\", 4:\"4.ì²­êµ¬ì…ê¸ˆì •ë³´\", \n",
    "               5:\"5.ì”ì•¡ì •ë³´\", 6:\"6.ì±„ë„ì •ë³´\", 7:\"7.ë§ˆì¼€íŒ…ì •ë³´\", 8:\"8.ì„±ê³¼ì •ë³´\"}\n",
    "\n",
    "# í˜„ì¬ ë””ë ‰í„°ë¦¬\n",
    "HOME = os.getcwd()\n",
    "\n",
    "# í´ë” ë¦¬ìŠ¤íŠ¸ ìƒì„± (ê²½ë¡œë¥¼ 'train'ì—ì„œ 'test'ë¡œ ë³€ê²½)\n",
    "folder_list = []\n",
    "for value in folder_name.values():\n",
    "    # âš ï¸ ì¤‘ìš”: ê²½ë¡œê°€ data/test ì¸ì§€ í™•ì¸í•˜ì„¸ìš”\n",
    "    folder_list.append(os.path.join(HOME, \"test\", value)) \n",
    "\n",
    "print(f\"ì´ í´ë” ê°œìˆ˜: {len(folder_list)}\")\n",
    "\n",
    "# í´ë” ë‚´ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ì½ì–´ì˜¤ê¸°\n",
    "fileNameList = {}\n",
    "for i in range(len(folder_list)):\n",
    "    # âš ï¸ íŒŒì¼ ìˆœì„œê°€ ì„ì´ì§€ ì•Šë„ë¡ sorted() ì¶”ê°€ (7ì›”, 8ì›”... ìˆœì„œ ë³´ì¥)\n",
    "    fileNameList[i+1] = sorted(os.listdir(folder_list[i]))\n",
    "    \n",
    "print(f\"ì²« ë²ˆì§¸ í´ë” íŒŒì¼ ëª©ë¡ ì˜ˆì‹œ: {fileNameList[1]}\")\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "filePathList = {}\n",
    "temp = []\n",
    "for i in range(len(folder_list)):\n",
    "    for j in range(len(fileNameList[i+1])):\n",
    "        temp.append(os.path.join(folder_list[i], fileNameList[i+1][j]))\n",
    "    filePathList[i+1] = temp\n",
    "    temp = []\n",
    "\n",
    "# ==========================================\n",
    "# 2. ë©”ëª¨ë¦¬ ìµœì í™” ë° ë³‘í•© í•¨ìˆ˜\n",
    "# ==========================================\n",
    "def optimize_memory(df):\n",
    "    for col in df.select_dtypes(include=['number']).columns:\n",
    "        if df[col].dtype == 'int64':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "        elif df[col].dtype == 'float64':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "    return df\n",
    "\n",
    "def create_Test_DataFrame(filePathList, month):\n",
    "    # month-7 ì¸ë±ì‹±ì„ ìœ„í•´ 7~12 ë²”ìœ„ í™•ì¸\n",
    "    if 7 <= month <= 12:\n",
    "        print(f\"{month}ì›” ë°ì´í„° ë³‘í•© ì‹œì‘...\")\n",
    "        for i in range(8): # 1ë²ˆ~8ë²ˆ í´ë” ìˆœíšŒ\n",
    "            \n",
    "            # íŒŒì¼ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸° (month-7 ì¸ë±ìŠ¤ ì‚¬ìš©)\n",
    "            # ì˜ˆ: 7ì›” -> index 0, 8ì›” -> index 1\n",
    "            current_file_path = filePathList[i+1][month-7]\n",
    "            \n",
    "            # ë‹¨ê³„ 1: ì½ê¸° ë° ìµœì í™”\n",
    "            # engine='fastparquet'ê°€ ì—†ìœ¼ë©´ pyarrow ë“± ê¸°ë³¸ ì—”ì§„ ì‚¬ìš©\n",
    "            try:\n",
    "                df = pd.read_parquet(current_file_path, engine=\"fastparquet\")\n",
    "            except:\n",
    "                df = pd.read_parquet(current_file_path) # ì—”ì§„ ì§€ì • ì—†ì´ ì¬ì‹œë„\n",
    "                \n",
    "            df = optimize_memory(df)\n",
    "            \n",
    "            # ë‹¨ê³„ 2: ë³‘í•©\n",
    "            if i == 0:\n",
    "                temp_df = df.copy()\n",
    "            else:\n",
    "                # ê¸°ì¤€ë…„ì›”, ID ê¸°ì¤€ìœ¼ë¡œ Left Join\n",
    "                temp_df = pd.merge(temp_df, df, on=[\"ê¸°ì¤€ë…„ì›”\", \"ID\"], how=\"left\")\n",
    "        \n",
    "        print(f\"âœ… {month}ì›” ë³‘í•© ì™„ë£Œ! í¬ê¸°: {temp_df.shape}\")\n",
    "        return temp_df\n",
    "    else:\n",
    "        print(\"Error: Month must be between 7 and 12\")\n",
    "        return None\n",
    "\n",
    "# ==========================================\n",
    "# 3. ì‹¤í–‰ ë° ì €ì¥\n",
    "# ==========================================\n",
    "\n",
    "# 7ì›”ë¶€í„° 12ì›”ê¹Œì§€ Test ë°ì´í„° ìƒì„± ë° ì €ì¥\n",
    "months = range(7, 13)\n",
    "\n",
    "for m in months:\n",
    "    # 1. ë³‘í•©\n",
    "    df_test_month = create_Test_DataFrame(filePathList, m)\n",
    "    \n",
    "    # 2. ì €ì¥ (íŒŒì¼ëª…: credit_test_month_X.parquet)\n",
    "    save_name = f\"credit_test_month_{m}.parquet\"\n",
    "    df_test_month.to_parquet(save_name)\n",
    "    print(f\"ğŸ’¾ {save_name} ì €ì¥ ì™„ë£Œ.\\n\")\n",
    "    \n",
    "    # 3. ë©”ëª¨ë¦¬ í•´ì œ\n",
    "    del df_test_month\n",
    "    gc.collect()\n",
    "\n",
    "print(\"ğŸ‰ ëª¨ë“  Test ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "619c9af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ ì›”ë³„ íŒŒì¼ ë³‘í•© ì‹œì‘ (7ì›”~12ì›”)...\n",
      " Â  - credit_preprocessing_month_7.parquet ë¡œë“œ ì™„ë£Œ\n",
      " Â  - credit_preprocessing_month_8.parquet ë¡œë“œ ì™„ë£Œ\n",
      " Â  - credit_preprocessing_month_9.parquet ë¡œë“œ ì™„ë£Œ\n",
      " Â  - credit_preprocessing_month_10.parquet ë¡œë“œ ì™„ë£Œ\n",
      " Â  - credit_preprocessing_month_11.parquet ë¡œë“œ ì™„ë£Œ\n",
      " Â  - credit_preprocessing_month_12.parquet ë¡œë“œ ì™„ë£Œ\n",
      "âœ… ë³‘í•© ì™„ë£Œ! ì „ì²´ ë°ì´í„° í¬ê¸°: (2400000, 858)\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# âœ… Step 1: ì›”ë³„ íŒŒì¼(7~12ì›”) ë³‘í•©\n",
    "# =========================================================\n",
    "FILE_PATH = r\"C:\\Users\\CY2\\github\\DataScience\\Credit Card\"\n",
    "months = range(7, 13)\n",
    "train_list = []\n",
    "\n",
    "print(\"ğŸ”„ ì›”ë³„ íŒŒì¼ ë³‘í•© ì‹œì‘ (7ì›”~12ì›”)...\")\n",
    "for m in months:\n",
    "    file_name = f\"credit_preprocessing_month_{m}.parquet\"\n",
    "    full_path = os.path.join(FILE_PATH, file_name)\n",
    "    if os.path.exists(full_path):\n",
    "        df = pd.read_parquet(full_path)\n",
    "        train_list.append(df)\n",
    "        print(f\" Â  - {file_name} ë¡œë“œ ì™„ë£Œ\")\n",
    "    else:\n",
    "        print(f\" Â  âš ï¸ íŒŒì¼ ì—†ìŒ: {file_name}\")\n",
    "\n",
    "# ì „ì²´ ë³‘í•© í›„ ë¦¬ìŠ¤íŠ¸ ì‚­ì œ (ë©”ëª¨ë¦¬ í™•ë³´)\n",
    "train = pd.concat(train_list, ignore_index=True)\n",
    "del train_list\n",
    "gc.collect()\n",
    "print(f\"âœ… ë³‘í•© ì™„ë£Œ! ì „ì²´ ë°ì´í„° í¬ê¸°: {train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d28daade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Test ë°ì´í„°(7~12ì›”) ë¡œë“œ ë° ë³‘í•© ì‹œì‘...\n",
      "   - credit_test_month_7.parquet ë¡œë“œ ì™„ë£Œ\n",
      "   - credit_test_month_8.parquet ë¡œë“œ ì™„ë£Œ\n",
      "   - credit_test_month_9.parquet ë¡œë“œ ì™„ë£Œ\n",
      "   - credit_test_month_10.parquet ë¡œë“œ ì™„ë£Œ\n",
      "   - credit_test_month_11.parquet ë¡œë“œ ì™„ë£Œ\n",
      "   - credit_test_month_12.parquet ë¡œë“œ ì™„ë£Œ\n",
      "\n",
      "âœ… Test ë°ì´í„° ë³‘í•© ì™„ë£Œ!\n",
      "   - ë°ì´í„° í¬ê¸°(Shape): (600000, 857)\n",
      "   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 1126.67 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# =========================================================\n",
    "# âœ… Step 1-2: Test ë°ì´í„° ë¡œë“œ ë° ë³‘í•© (7~12ì›”)\n",
    "# =========================================================\n",
    "FILE_PATH = r\"C:\\Users\\CY2\\github\\DataScience\\Credit Card\"\n",
    "months = range(7, 13)\n",
    "test_list = []\n",
    "\n",
    "print(\"ğŸ”„ Test ë°ì´í„°(7~12ì›”) ë¡œë“œ ë° ë³‘í•© ì‹œì‘...\")\n",
    "\n",
    "for m in months:\n",
    "    # ì‚¬ìš©ìë‹˜ì´ ë§Œë“œì‹  íŒŒì¼ëª… ê·œì¹™ ì ìš©\n",
    "    file_name = f\"credit_test_month_{m}.parquet\"\n",
    "    full_path = os.path.join(FILE_PATH, file_name)\n",
    "    \n",
    "    if os.path.exists(full_path):\n",
    "        # fastparquet ì—”ì§„ ì‚¬ìš© (ì†ë„ ë° í˜¸í™˜ì„±)\n",
    "        try:\n",
    "            df = pd.read_parquet(full_path, engine='fastparquet')\n",
    "        except:\n",
    "            df = pd.read_parquet(full_path) # ì—”ì§„ ì§€ì • ì—†ì´ ì¬ì‹œë„\n",
    "            \n",
    "        test_list.append(df)\n",
    "        print(f\"   - {file_name} ë¡œë“œ ì™„ë£Œ\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸ íŒŒì¼ ì—†ìŒ: {file_name} (ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”)\")\n",
    "\n",
    "# ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆì§€ ì•Šë‹¤ë©´ ë³‘í•© ì§„í–‰\n",
    "if test_list:\n",
    "    # 1. í•˜ë‚˜ë¡œ ë³‘í•©\n",
    "    test = pd.concat(test_list, ignore_index=True)\n",
    "    \n",
    "    # 2. ë©”ëª¨ë¦¬ ì •ë¦¬ (ë¦¬ìŠ¤íŠ¸ ì‚­ì œ)\n",
    "    del test_list\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"\\nâœ… Test ë°ì´í„° ë³‘í•© ì™„ë£Œ!\")\n",
    "    print(f\"   - ë°ì´í„° í¬ê¸°(Shape): {test.shape}\")\n",
    "    print(f\"   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {test.memory_usage().sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # (ì„ íƒì‚¬í•­) ë³‘í•©ëœ íŒŒì¼ ì €ì¥í•´ë‘ê¸° - í•„ìš” ì—†ìœ¼ë©´ ì£¼ì„ ì²˜ë¦¬\n",
    "    # test.to_parquet(os.path.join(FILE_PATH, \"test_merged_7_12.parquet\"), index=False)\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œì™€ íŒŒì¼ëª…ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "625f58ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ Step 2: ì „ì²˜ë¦¬ (ì¸ì½”ë”©, ê²°ì¸¡ì¹˜, ì´ìƒì¹˜ ì²˜ë¦¬) ì‹œì‘...\n",
      "   [1/4] íƒ€ê²Ÿ ë³€ìˆ˜ ì¸ì½”ë”© ì¤‘...\n",
      "      - íƒ€ê²Ÿ í´ë˜ìŠ¤ ê°œìˆ˜: 5ê°œ (['A' 'B' 'C' 'D' 'E'])\n",
      "   [2/4] íŠ¹ì§•(X)ê³¼ ì •ë‹µ(y) ë¶„ë¦¬ ë° ë©”ëª¨ë¦¬ ì •ë¦¬...\n",
      "      - ìˆ˜ì¹˜í˜• ë³€ìˆ˜: 808ê°œ\n",
      "      - ë²”ì£¼í˜• ë³€ìˆ˜: 48ê°œ\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats.mstats import winsorize\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =========================================================\n",
    "# âœ… Step 2: ì „ì²˜ë¦¬ (5ë“± ë¶„ì„ê°€ ë¡œì§ ì ìš©)\n",
    "# =========================================================\n",
    "print(\"\\nğŸ”„ Step 2: ì „ì²˜ë¦¬ (ì¸ì½”ë”©, ê²°ì¸¡ì¹˜, ì´ìƒì¹˜ ì²˜ë¦¬) ì‹œì‘...\")\n",
    "start_time_step2 = time.time()\n",
    "\n",
    "# 1. íƒ€ê²Ÿ ì»¬ëŸ¼ ë° ID ì»¬ëŸ¼ ì„¤ì • (ë°ì´í„°ì— ë§ê²Œ ìˆ˜ì • í•„ìš”)\n",
    "TARGET_COLUMN = 'Segment'  # í˜¹ì€ 'N_Category'\n",
    "ID_COLUMN = 'ID'\n",
    "\n",
    "# 2. íƒ€ê²Ÿ ë³€ìˆ˜ ì¸ì½”ë”© (LabelEncoder)\n",
    "print(\"   [1/4] íƒ€ê²Ÿ ë³€ìˆ˜ ì¸ì½”ë”© ì¤‘...\")\n",
    "if TARGET_COLUMN in train.columns:\n",
    "    y = train[TARGET_COLUMN].copy()\n",
    "    le_target = LabelEncoder()\n",
    "    # ì•ˆì „í•˜ê²Œ ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ ì¸ì½”ë”© (ìˆ«ì/ë¬¸ì í˜¼ìš© ë°©ì§€)\n",
    "    y_encoded = le_target.fit_transform(y.astype(str))\n",
    "    num_classes = len(le_target.classes_)\n",
    "    print(f\"      - íƒ€ê²Ÿ í´ë˜ìŠ¤ ê°œìˆ˜: {num_classes}ê°œ ({le_target.classes_})\")\n",
    "else:\n",
    "    raise ValueError(f\"âŒ Error: Train ë°ì´í„°ì— '{TARGET_COL}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# 3. ë°ì´í„° ë¶„ë¦¬ ë° ë©”ëª¨ë¦¬ í™•ë³´\n",
    "print(\"   [2/4] íŠ¹ì§•(X)ê³¼ ì •ë‹µ(y) ë¶„ë¦¬ ë° ë©”ëª¨ë¦¬ ì •ë¦¬...\")\n",
    "# Trainì—ì„œ ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°\n",
    "X = train.drop(columns=[ID_COLUMN, TARGET_COLUMN] if ID_COLUMN in train.columns else [TARGET_COLUMN])\n",
    "\n",
    "# Testì—ì„œ ID ë¶„ë¦¬ ë° ë¶ˆí•„ìš” ì»¬ëŸ¼ ì œê±°\n",
    "if ID_COLUMN in test.columns:\n",
    "    test_ids = test[ID_COLUMN].copy()\n",
    "    X_test = test.drop(columns=[ID_COLUMN])\n",
    "else:\n",
    "    test_ids = test.index # ID ì»¬ëŸ¼ ì—†ìœ¼ë©´ ì¸ë±ìŠ¤ ì‚¬ìš©\n",
    "    X_test = test.copy()\n",
    "\n",
    "# âš ï¸ í•µì‹¬: ì›ë³¸ ë°ì´í„° ì‚­ì œë¡œ ë©”ëª¨ë¦¬ í™•ë³´ (8GB í™˜ê²½ í•„ìˆ˜)\n",
    "del train, test, y\n",
    "gc.collect()\n",
    "\n",
    "# ìˆ˜ì¹˜í˜•/ë²”ì£¼í˜• ì»¬ëŸ¼ ìë™ ë¶„ë¥˜\n",
    "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "print(f\"      - ìˆ˜ì¹˜í˜• ë³€ìˆ˜: {len(numerical_features)}ê°œ\")\n",
    "print(f\"      - ë²”ì£¼í˜• ë³€ìˆ˜: {len(categorical_features)}ê°œ\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "04ddf870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 4. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (SimpleImputer)\n",
    "# print(\"   [3/4] ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (Median & Most Frequent)...\")\n",
    "\n",
    "# # ìˆ˜ì¹˜í˜•: ì¤‘ì•™ê°’(Median)\n",
    "# if numerical_features:\n",
    "#     num_imputer = SimpleImputer(strategy='median')\n",
    "#     X[numerical_features] = num_imputer.fit_transform(X[numerical_features])\n",
    "#     # Test ë°ì´í„°ëŠ” Trainì˜ ì¤‘ì•™ê°’ ê¸°ì¤€ìœ¼ë¡œ ì±„ì›€ (Data Leakage ë°©ì§€)\n",
    "#     X_test[numerical_features] = num_imputer.transform(X_test[numerical_features])\n",
    "\n",
    "# # ë²”ì£¼í˜•: ìµœë¹ˆê°’(Most Frequent)\n",
    "# if categorical_features:\n",
    "#     cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "#     X[categorical_features] = cat_imputer.fit_transform(X[categorical_features])\n",
    "#     X_test[categorical_features] = cat_imputer.transform(X_test[categorical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661a4523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [3/4] ë©”ëª¨ë¦¬ ì ˆì•½í˜• ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì‹œì‘...\n",
      "      - ìˆ˜ì¹˜í˜• ë³€ìˆ˜ 808ê°œ ì²˜ë¦¬ ì¤‘...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[76]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m         \u001b[38;5;66;03m# Train/Test ê°ê° ì±„ìš°ê¸° (inplace=Trueì™€ ìœ ì‚¬í•œ ë°©ì‹ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½)\u001b[39;00m\n\u001b[32m     14\u001b[39m         X[col] = X[col].fillna(median_val).astype(\u001b[33m'\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m         X_test[col] = \u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmedian_val\u001b[49m\u001b[43m)\u001b[49m.astype(\u001b[33m'\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     16\u001b[39m     gc.collect() \u001b[38;5;66;03m# ì¤‘ê°„ ë©”ëª¨ë¦¬ ì •ë¦¬\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# 2. ë²”ì£¼í˜• ë³€ìˆ˜: ìµœë¹ˆê°’(Most Frequent)ìœ¼ë¡œ ì±„ìš°ê¸°\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CY2\\miniconda3\\envs\\DS\\Lib\\site-packages\\pandas\\core\\generic.py:7086\u001b[39m, in \u001b[36mNDFrame.fillna\u001b[39m\u001b[34m(self, value, axis, inplace, limit)\u001b[39m\n\u001b[32m   7079\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   7080\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   7081\u001b[39m             \u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m parameter must be a scalar, dict \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   7082\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mor Series, but you passed a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   7083\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   7084\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m7086\u001b[39m     new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7088\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mdict\u001b[39m, ABCSeries)):\n\u001b[32m   7089\u001b[39m     result = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CY2\\miniconda3\\envs\\DS\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:458\u001b[39m, in \u001b[36mBaseBlockManager.fillna\u001b[39m\u001b[34m(self, value, limit, inplace)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    455\u001b[39m     \u001b[38;5;66;03m# Do this validation even if we go through one of the no-op paths\u001b[39;00m\n\u001b[32m    456\u001b[39m     limit = libalgos.validate_limit(\u001b[38;5;28;01mNone\u001b[39;00m, limit=limit)\n\u001b[32m--> \u001b[39m\u001b[32m458\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfillna\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CY2\\miniconda3\\envs\\DS\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:442\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    440\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    443\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    445\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, [ax.view() \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.axes])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CY2\\miniconda3\\envs\\DS\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1331\u001b[39m, in \u001b[36mBlock.fillna\u001b[39m\u001b[34m(self, value, limit, inplace)\u001b[39m\n\u001b[32m   1329\u001b[39m     noop = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1330\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1331\u001b[39m     mask = \u001b[43misna\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1332\u001b[39m     mask, noop = validate_putmask(\u001b[38;5;28mself\u001b[39m.values, mask)\n\u001b[32m   1334\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m noop:\n\u001b[32m   1335\u001b[39m     \u001b[38;5;66;03m# we can't process the value, but nothing to do\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CY2\\miniconda3\\envs\\DS\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:174\u001b[39m, in \u001b[36misna\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;129m@set_module\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpandas\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34misna\u001b[39m(obj: \u001b[38;5;28mobject\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m | npt.NDArray[np.bool_] | NDFrame:\n\u001b[32m     99\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03m    Detect missing values for an array-like object.\u001b[39;00m\n\u001b[32m    101\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    172\u001b[39m \u001b[33;03m    Name: 1, dtype: bool\u001b[39;00m\n\u001b[32m    173\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_isna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CY2\\miniconda3\\envs\\DS\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:200\u001b[39m, in \u001b[36m_isna\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (np.ndarray, ABCExtensionArray)):\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_isna_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, ABCIndex):\n\u001b[32m    202\u001b[39m     \u001b[38;5;66;03m# Try to use cached isna, which also short-circuits for integer dtypes\u001b[39;00m\n\u001b[32m    203\u001b[39m     \u001b[38;5;66;03m#  and avoids materializing RangeIndex._values\u001b[39;00m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m obj._can_hold_na:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CY2\\miniconda3\\envs\\DS\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:255\u001b[39m, in \u001b[36m_isna_array\u001b[39m\u001b[34m(values)\u001b[39m\n\u001b[32m    253\u001b[39m     result = values.view(\u001b[33m\"\u001b[39m\u001b[33mi8\u001b[39m\u001b[33m\"\u001b[39m) == iNaT\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m     result = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# # ë©”ëª¨ë¦¬ í„°ì§€ë©´ ì´ê±°ì¨!\n",
    "# # ì˜¤ë˜ê±¸ë ¤ë„ ë©”ëª¨ë¦¬ëŠ” ì•ˆí„°ì§€ëŠ”ë°©ë²•\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# print(\"   [3/4] ë©”ëª¨ë¦¬ ì ˆì•½í˜• ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì‹œì‘...\")\n",
    "\n",
    "# # 1. ìˆ˜ì¹˜í˜• ë³€ìˆ˜: ì¤‘ì•™ê°’(Median)ìœ¼ë¡œ ì±„ìš°ê¸°\n",
    "# if numerical_features:\n",
    "#     print(f\"      - ìˆ˜ì¹˜í˜• ë³€ìˆ˜ {len(numerical_features)}ê°œ ì²˜ë¦¬ ì¤‘...\")\n",
    "#     for col in numerical_features:\n",
    "#         # Train ë°ì´í„°ì˜ ì¤‘ì•™ê°’ ê³„ì‚°\n",
    "#         median_val = X[col].median()\n",
    "#         # Train/Test ê°ê° ì±„ìš°ê¸° (inplace=Trueì™€ ìœ ì‚¬í•œ ë°©ì‹ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½)\n",
    "#         X[col] = X[col].fillna(median_val).astype('float32')\n",
    "#         X_test[col] = X_test[col].fillna(median_val).astype('float32')\n",
    "#     gc.collect() # ì¤‘ê°„ ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "\n",
    "# # 2. ë²”ì£¼í˜• ë³€ìˆ˜: ìµœë¹ˆê°’(Most Frequent)ìœ¼ë¡œ ì±„ìš°ê¸°\n",
    "# if categorical_features:\n",
    "#     print(f\"      - ë²”ì£¼í˜• ë³€ìˆ˜ {len(categorical_features)}ê°œ ì²˜ë¦¬ ì¤‘...\")\n",
    "#     for col in categorical_features:\n",
    "#         # ìµœë¹ˆê°’ì´ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ì˜ˆì™¸ ì²˜ë¦¬\n",
    "#         mode_series = X[col].mode()\n",
    "#         if not mode_series.empty:\n",
    "#             mode_val = mode_series[0]\n",
    "#             X[col] = X[col].fillna(mode_val)\n",
    "#             X_test[col] = X_test[col].fillna(mode_val)\n",
    "#     gc.collect()\n",
    "\n",
    "# print(\"   âœ… ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë° float32 í˜•ë³€í™˜ ì™„ë£Œ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23b21c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [3/4] ì´ˆê³ ì†+ì €ìš©ëŸ‰ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì‹œì‘...\n",
      "      - ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ì¤‘ì•™ê°’ ê³„ì‚° ì¤‘...\n",
      "      - 808ê°œ ì»¬ëŸ¼ ê²°ì¸¡ì¹˜ ì±„ìš°ê¸° ì‹œì‘...\n",
      "      - ë²”ì£¼í˜• ë³€ìˆ˜ ìµœë¹ˆê°’ ê³„ì‚° ì¤‘...\n",
      "   âœ… ìµœì í™” ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ.\n"
     ]
    }
   ],
   "source": [
    "# ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ëŠë¦´ë–„ \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(\"   [3/4] ì´ˆê³ ì†+ì €ìš©ëŸ‰ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì‹œì‘...\")\n",
    "\n",
    "if numerical_features:\n",
    "    # 1. ì¤‘ì•™ê°’ì„ í•œêº¼ë²ˆì— ê³„ì‚° (ì´ê±´ ë©”ëª¨ë¦¬ë¥¼ ìƒê°ë³´ë‹¤ ë§ì´ ì•ˆ ë¨¹ìŠµë‹ˆë‹¤)\n",
    "    print(\"      - ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ì¤‘ì•™ê°’ ê³„ì‚° ì¤‘...\")\n",
    "    medians = X[numerical_features].median() \n",
    "    \n",
    "    # 2. ì±„ìš°ê¸° ì‘ì—…ë§Œ ë£¨í”„ë¡œ ì§„í–‰ (ì´ë¯¸ ê³„ì‚°ëœ ê°’ì„ ì“°ë¯€ë¡œ í›¨ì”¬ ë¹ ë¦„)\n",
    "    print(f\"      - {len(numerical_features)}ê°œ ì»¬ëŸ¼ ê²°ì¸¡ì¹˜ ì±„ìš°ê¸° ì‹œì‘...\")\n",
    "    for col in numerical_features:\n",
    "        X[col] = X[col].fillna(medians[col]).astype('float32')\n",
    "        X_test[col] = X_test[col].fillna(medians[col]).astype('float32')\n",
    "    gc.collect()\n",
    "\n",
    "# ë²”ì£¼í˜•ë„ ë™ì¼í•˜ê²Œ ìµœë¹ˆê°’ ë¯¸ë¦¬ ê³„ì‚°\n",
    "if categorical_features:\n",
    "    print(\"      - ë²”ì£¼í˜• ë³€ìˆ˜ ìµœë¹ˆê°’ ê³„ì‚° ì¤‘...\")\n",
    "    modes = X[categorical_features].mode().iloc[0]\n",
    "    \n",
    "    for col in categorical_features:\n",
    "        X[col] = X[col].fillna(modes[col])\n",
    "        X_test[col] = X_test[col].fillna(modes[col])\n",
    "    gc.collect()\n",
    "\n",
    "print(\"   âœ… ìµœì í™” ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1854667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [4/4] ì´ìƒì¹˜ ì²˜ë¦¬ (Winsorization ìƒí•˜ìœ„ 1%)...\n",
      "âœ… Step 2 ì™„ë£Œ. (ì†Œìš” ì‹œê°„: 123.26 ì´ˆ)\n",
      "   - ìµœì¢… í•™ìŠµ ë°ì´í„° í¬ê¸°: (2400000, 856)\n",
      "   - ìµœì¢… í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: (600000, 856)\n"
     ]
    }
   ],
   "source": [
    "# 5. ì´ìƒì¹˜ ì²˜ë¦¬ (Winsorization & Clipping) - 5ë“± ë¶„ì„ê°€ í•µì‹¬\n",
    "print(\"   [4/4] ì´ìƒì¹˜ ì²˜ë¦¬ (Winsorization ìƒí•˜ìœ„ 1%)...\")\n",
    "winsorize_alpha = 0.01 # ìƒí•˜ìœ„ 1%\n",
    "\n",
    "for col in numerical_features:\n",
    "    # Train: ìƒí•˜ìœ„ 1% ê°’ì„ ê²½ê³„ê°’ìœ¼ë¡œ ë³€í™˜ (Winsorization)\n",
    "    X[col] = winsorize(X[col], limits=(winsorize_alpha, winsorize_alpha))\n",
    "    \n",
    "    # Test: Trainì—ì„œ ê³„ì‚°ëœ ê²½ê³„ê°’(1%, 99%)ì„ ê¸°ì¤€ìœ¼ë¡œ ìë¦„ (Clipping)\n",
    "    # âš ï¸ Test ë°ì´í„°ì— ì§ì ‘ winsorizeë¥¼ ì“°ë©´ ì•ˆ ë¨ (ê¸°ì¤€ì´ ë‹¬ë¼ì§)\n",
    "    q_low = np.percentile(X[col], winsorize_alpha * 100)\n",
    "    q_high = np.percentile(X[col], (1 - winsorize_alpha) * 100)\n",
    "    X_test[col] = np.clip(X_test[col], q_low, q_high)\n",
    "\n",
    "end_time_step2 = time.time()\n",
    "print(f\"âœ… Step 2 ì™„ë£Œ. (ì†Œìš” ì‹œê°„: {end_time_step2 - start_time_step2:.2f} ì´ˆ)\")\n",
    "print(f\"   - ìµœì¢… í•™ìŠµ ë°ì´í„° í¬ê¸°: {X.shape}\")\n",
    "print(f\"   - ìµœì¢… í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e76bbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ ë¶„ì‚°ì´ 0ì¸ ë³€ìˆ˜(ëª¨ë“  ê°’ì´ ë˜‘ê°™ì€ ì»¬ëŸ¼) íƒìƒ‰ ë° ì œê±° ì‹œì‘...\n",
      "   ğŸš¨ ì´ 226ê°œì˜ ì˜ë¯¸ ì—†ëŠ” ë³€ìˆ˜(ìƒìˆ˜)ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.\n",
      "      ì˜ˆì‹œ: ['ìœ íš¨ì¹´ë“œìˆ˜_ì²´í¬_ê°€ì¡±', 'ì´ìš©ê°€ëŠ¥ì¹´ë“œìˆ˜_ì²´í¬_ê°€ì¡±', 'ì´ìš©ì¹´ë“œìˆ˜_ì²´í¬_ê°€ì¡±', 'ì´ìš©ê¸ˆì•¡_R3M_ì²´í¬_ê°€ì¡±', 'ì—°íšŒë¹„í• ì¸ì¹´ë“œìˆ˜_B0M'] ...\n",
      "   âœ… ì œê±° ì™„ë£Œ.\n",
      "   -> í˜„ì¬ ë‚¨ì€ ì „ì²´ í”¼ì²˜ ìˆ˜: 630ê°œ\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "def remove_zero_variance_features(X, X_test, numerical_features):\n",
    "    print(\"ğŸ”„ ë¶„ì‚°ì´ 0ì¸ ë³€ìˆ˜(ëª¨ë“  ê°’ì´ ë˜‘ê°™ì€ ì»¬ëŸ¼) íƒìƒ‰ ë° ì œê±° ì‹œì‘...\")\n",
    "    \n",
    "    # 1. ì œê±°í•  ì»¬ëŸ¼ ì°¾ê¸° (Forë¬¸ìœ¼ë¡œ ê°€ë³ê²Œ ê²€ì‚¬)\n",
    "    cols_to_drop = []\n",
    "    \n",
    "    # ì „ì²´ë¥¼ í•œ ë²ˆì— ê³„ì‚°í•˜ì§€ ì•Šê³  í•˜ë‚˜ì”© í™•ì¸í•´ì„œ ë©”ëª¨ë¦¬ ë³´í˜¸\n",
    "    for col in numerical_features:\n",
    "        if col in X.columns:\n",
    "            # ìµœì†Œê°’ê³¼ ìµœëŒ€ê°’ì´ ê°™ìœ¼ë©´ -> ëª¨ë“  ê°’ì´ ë˜‘ê°™ë‹¤ëŠ” ëœ» (ë¶„ì‚° 0)\n",
    "            # (ê²°ì¸¡ì¹˜ê°€ ì´ë¯¸ ì²˜ë¦¬ëœ ìƒíƒœë¼ê³  ê°€ì •)\n",
    "            if X[col].min() == X[col].max():\n",
    "                cols_to_drop.append(col)\n",
    "    \n",
    "    # 2. ì‹¤ì œ ì œê±° ì‘ì—…\n",
    "    if cols_to_drop:\n",
    "        print(f\"   ğŸš¨ ì´ {len(cols_to_drop)}ê°œì˜ ì˜ë¯¸ ì—†ëŠ” ë³€ìˆ˜(ìƒìˆ˜)ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.\")\n",
    "        print(f\"      ì˜ˆì‹œ: {cols_to_drop[:5]} ...\")\n",
    "        \n",
    "        # inplace=Trueë¡œ ë©”ëª¨ë¦¬ ë³µì‚¬ ì—†ì´ ì¦‰ì‹œ ì‚­ì œ\n",
    "        X.drop(columns=cols_to_drop, inplace=True)\n",
    "        # Test ë°ì´í„°ì—ì„œë„ ë˜‘ê°™ì´ ì‚­ì œ\n",
    "        X_test.drop(columns=cols_to_drop, inplace=True)\n",
    "        \n",
    "        # ê´€ë¦¬ ì¤‘ì¸ ë¦¬ìŠ¤íŠ¸ì—ì„œë„ ì‚­ì œ\n",
    "        numerical_features = [c for c in numerical_features if c not in cols_to_drop]\n",
    "        print(\"   âœ… ì œê±° ì™„ë£Œ.\")\n",
    "    else:\n",
    "        print(\"   âœ… ì œê±°í•  ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. (ëª¨ë“  ë³€ìˆ˜ê°€ ë³€í™”ëŸ‰ì´ ìˆìŒ)\")\n",
    "        \n",
    "    print(f\"   -> í˜„ì¬ ë‚¨ì€ ì „ì²´ í”¼ì²˜ ìˆ˜: {X.shape[1]}ê°œ\")\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ ì²­ì†Œ\n",
    "    gc.collect()\n",
    "    \n",
    "    return X, X_test, numerical_features\n",
    "\n",
    "# ==========================================\n",
    "# ì‹¤í–‰\n",
    "# ==========================================\n",
    "X, X_test, numerical_features = remove_zero_variance_features(X, X_test, numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae04068b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ ë¡œê·¸ ë³€í™˜ (Log Transformation) ì‹œì‘...\n",
      "   -> ëŒ€ìƒ ì»¬ëŸ¼: 208ê°œ ë°œê²¬\n",
      "   âœ… 208ê°œ ë³€ìˆ˜ì— ëŒ€í•´ ë¡œê·¸ ë³€í™˜ ì™„ë£Œ!\n",
      "   -> í˜„ì¬ ì „ì²´ í”¼ì²˜ ìˆ˜: 838ê°œ\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "def apply_log_transformation(X, X_test, numerical_features):\n",
    "    print(\"ğŸ”„ ë¡œê·¸ ë³€í™˜ (Log Transformation) ì‹œì‘...\")\n",
    "    \n",
    "    # 1. ë¡œê·¸ ë³€í™˜ ëŒ€ìƒ ì»¬ëŸ¼ ì°¾ê¸°\n",
    "    # ê¸ˆì•¡, ì›ê¸ˆ, í‰ì” ë“±ì˜ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì»¬ëŸ¼ì„ ì°¾ìŠµë‹ˆë‹¤.\n",
    "    # ì´ë¯¸ '_log1p'ê°€ ë¶™ì€ ì»¬ëŸ¼ì€ ì œì™¸í•©ë‹ˆë‹¤ (ì¤‘ë³µ ë°©ì§€).\n",
    "    log_keywords = ['ê¸ˆì•¡', 'ì›ê¸ˆ', 'í‰ì”', 'Amount', 'Balance']\n",
    "    target_cols = [c for c in numerical_features if any(k in c for k in log_keywords) and '_log1p' not in c]\n",
    "    \n",
    "    print(f\"   -> ëŒ€ìƒ ì»¬ëŸ¼: {len(target_cols)}ê°œ ë°œê²¬\")\n",
    "    \n",
    "    added_features = []\n",
    "    \n",
    "    # 2. ë³€í™˜ ìˆ˜í–‰ (í•œ ë²ˆì— í•˜ë‚˜ì”© ì²˜ë¦¬í•˜ì—¬ ë©”ëª¨ë¦¬ ë³´í˜¸)\n",
    "    for col in target_cols:\n",
    "        if col in X.columns:\n",
    "            new_col_name = f\"{col}_log1p\"\n",
    "            \n",
    "            # (1) í•™ìŠµ ë°ì´í„°(X) ë³€í™˜\n",
    "            # ìŒìˆ˜ê°€ ìˆëŠ” ê²½ìš° ìµœì†Ÿê°’ì„ ë¹¼ì„œ ì–‘ìˆ˜ë¡œ ë§Œë“  ë’¤ ë¡œê·¸ ì ìš©\n",
    "            min_val = X[col].min()\n",
    "            if min_val < 0:\n",
    "                X[new_col_name] = np.log1p(X[col] - min_val).astype('float32')\n",
    "                # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ë„ ë˜‘ê°™ì€ min_valì„ ì ìš©í•´ì•¼ í•¨ (ê¸°ì¤€ í†µì¼)\n",
    "                if col in X_test.columns:\n",
    "                    X_test[new_col_name] = np.log1p(X_test[col] - min_val).astype('float32')\n",
    "            else:\n",
    "                X[new_col_name] = np.log1p(X[col]).astype('float32')\n",
    "                if col in X_test.columns:\n",
    "                    X_test[new_col_name] = np.log1p(X_test[col]).astype('float32')\n",
    "            \n",
    "            added_features.append(new_col_name)\n",
    "\n",
    "    # 3. ìƒˆë¡œìš´ ì»¬ëŸ¼ì„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "    numerical_features.extend(added_features)\n",
    "    \n",
    "    print(f\"   âœ… {len(added_features)}ê°œ ë³€ìˆ˜ì— ëŒ€í•´ ë¡œê·¸ ë³€í™˜ ì™„ë£Œ!\")\n",
    "    print(f\"   -> í˜„ì¬ ì „ì²´ í”¼ì²˜ ìˆ˜: {X.shape[1]}ê°œ\")\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ ì²­ì†Œ\n",
    "    gc.collect()\n",
    "    \n",
    "    return X, X_test, numerical_features\n",
    "\n",
    "# ==========================================\n",
    "# ì‹¤í–‰\n",
    "# ==========================================\n",
    "X, X_test, numerical_features = apply_log_transformation(X, X_test, numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd331db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ í‰ê·  ê±°ë˜ ê¸ˆì•¡ (Average Transaction Amount) ìƒì„± ì¤‘...\n",
      "   -> 'ì´ì´ìš©ê¸ˆì•¡_R12M' ìƒì„± (ëŒ€ìƒ ì»¬ëŸ¼ 16ê°œ í•©ì‚°)\n",
      "   -> 'ì´ì´ìš©ê±´ìˆ˜_R12M' ìƒì„± (ëŒ€ìƒ ì»¬ëŸ¼ 9ê°œ í•©ì‚°)\n",
      "   âœ… 'í‰ê· ê±°ë˜ê¸ˆì•¡_R12M' ìƒì„± ì™„ë£Œ!\n",
      "   -> í˜„ì¬ ì „ì²´ í”¼ì²˜ ìˆ˜: 841ê°œ\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "def create_avg_transaction_feature(X, X_test, numerical_features):\n",
    "    print(\"ğŸ”„ í‰ê·  ê±°ë˜ ê¸ˆì•¡ (Average Transaction Amount) ìƒì„± ì¤‘...\")\n",
    "    \n",
    "    epsilon = 1e-6 # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€ìš© ì•„ì£¼ ì‘ì€ ìˆ˜\n",
    "    \n",
    "    # 1. 'ì´ ì´ìš©ê¸ˆì•¡'ê³¼ 'ì´ ì´ìš©ê±´ìˆ˜' ì»¬ëŸ¼ ì¤€ë¹„\n",
    "    # (ì´ë¯¸ ë§Œë“¤ì–´ì ¸ ìˆë‹¤ë©´ ê°€ì ¸ë‹¤ ì“°ê³ , ì—†ë‹¤ë©´ ì§€ê¸ˆ ê³„ì‚°í•©ë‹ˆë‹¤)\n",
    "    \n",
    "    # [A] ì´ ì´ìš©ê¸ˆì•¡ (R12M: ìµœê·¼ 1ë…„)\n",
    "    if 'ì´ì´ìš©ê¸ˆì•¡_R12M' not in X.columns:\n",
    "        amt_cols = [c for c in X.columns if 'ì´ìš©ê¸ˆì•¡' in c and 'R12M' in c and '_log1p' not in c]\n",
    "        if amt_cols:\n",
    "            print(f\"   -> 'ì´ì´ìš©ê¸ˆì•¡_R12M' ìƒì„± (ëŒ€ìƒ ì»¬ëŸ¼ {len(amt_cols)}ê°œ í•©ì‚°)\")\n",
    "            X['ì´ì´ìš©ê¸ˆì•¡_R12M'] = X[amt_cols].sum(axis=1).astype('float32')\n",
    "            if 'ì´ì´ìš©ê¸ˆì•¡_R12M' not in numerical_features: numerical_features.append('ì´ì´ìš©ê¸ˆì•¡_R12M')\n",
    "            \n",
    "            # Test ë°ì´í„°ë„ ë™ì¼í•˜ê²Œ\n",
    "            if set(amt_cols).issubset(X_test.columns):\n",
    "                X_test['ì´ì´ìš©ê¸ˆì•¡_R12M'] = X_test[amt_cols].sum(axis=1).astype('float32')\n",
    "\n",
    "    # [B] ì´ ì´ìš©ê±´ìˆ˜ (R12M: ìµœê·¼ 1ë…„)\n",
    "    if 'ì´ì´ìš©ê±´ìˆ˜_R12M' not in X.columns:\n",
    "        cnt_cols = [c for c in X.columns if 'ì´ìš©ê±´ìˆ˜' in c and 'R12M' in c]\n",
    "        if cnt_cols:\n",
    "            print(f\"   -> 'ì´ì´ìš©ê±´ìˆ˜_R12M' ìƒì„± (ëŒ€ìƒ ì»¬ëŸ¼ {len(cnt_cols)}ê°œ í•©ì‚°)\")\n",
    "            X['ì´ì´ìš©ê±´ìˆ˜_R12M'] = X[cnt_cols].sum(axis=1).astype('float32')\n",
    "            if 'ì´ì´ìš©ê±´ìˆ˜_R12M' not in numerical_features: numerical_features.append('ì´ì´ìš©ê±´ìˆ˜_R12M')\n",
    "            \n",
    "            # Test ë°ì´í„°ë„ ë™ì¼í•˜ê²Œ\n",
    "            if set(cnt_cols).issubset(X_test.columns):\n",
    "                X_test['ì´ì´ìš©ê±´ìˆ˜_R12M'] = X_test[cnt_cols].sum(axis=1).astype('float32')\n",
    "\n",
    "    # 2. í‰ê·  ê±°ë˜ ê¸ˆì•¡ ê³„ì‚° (ê¸ˆì•¡ / ê±´ìˆ˜)\n",
    "    if 'ì´ì´ìš©ê¸ˆì•¡_R12M' in X.columns and 'ì´ì´ìš©ê±´ìˆ˜_R12M' in X.columns:\n",
    "        new_col = 'í‰ê· ê±°ë˜ê¸ˆì•¡_R12M'\n",
    "        \n",
    "        # Train ê³„ì‚°\n",
    "        # (ê±´ìˆ˜ì— epsilonì„ ë”í•´ì„œ 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì„ ë°©ì§€)\n",
    "        X[new_col] = (X['ì´ì´ìš©ê¸ˆì•¡_R12M'] / (X['ì´ì´ìš©ê±´ìˆ˜_R12M'] + epsilon)).astype('float32')\n",
    "        \n",
    "        # Test ê³„ì‚°\n",
    "        if 'ì´ì´ìš©ê¸ˆì•¡_R12M' in X_test.columns and 'ì´ì´ìš©ê±´ìˆ˜_R12M' in X_test.columns:\n",
    "            X_test[new_col] = (X_test['ì´ì´ìš©ê¸ˆì•¡_R12M'] / (X_test['ì´ì´ìš©ê±´ìˆ˜_R12M'] + epsilon)).astype('float32')\n",
    "            \n",
    "        numerical_features.append(new_col)\n",
    "        print(f\"   âœ… '{new_col}' ìƒì„± ì™„ë£Œ!\")\n",
    "    else:\n",
    "        print(\"   âš ï¸ ì£¼ì˜: 'ì´ìš©ê¸ˆì•¡'ì´ë‚˜ 'ì´ìš©ê±´ìˆ˜' ê´€ë ¨ ì»¬ëŸ¼ì´ ì—†ì–´ì„œ í‰ê· ê¸ˆì•¡ì„ ë§Œë“¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    print(f\"   -> í˜„ì¬ ì „ì²´ í”¼ì²˜ ìˆ˜: {X.shape[1]}ê°œ\")\n",
    "    gc.collect()\n",
    "    \n",
    "    return X, X_test, numerical_features\n",
    "\n",
    "# ==========================================\n",
    "# ì‹¤í–‰\n",
    "# ==========================================\n",
    "X, X_test, numerical_features = create_avg_transaction_feature(X, X_test, numerical_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36339a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ ì†Œë¹„ íŒ¨í„´ ë° ì‹ ìš© ë¦¬ìŠ¤í¬ íŒŒìƒë³€ìˆ˜ ìƒì„± ì¤‘...\n",
      "   -> [íŒ¨í„´] ì˜¨ë¼ì¸ ê´€ë ¨ ì»¬ëŸ¼ 7ê°œ ë°œê²¬. ë¹„ì¤‘ ê³„ì‚° ì¤‘...\n",
      "   -> [íŒ¨í„´] ìµœê·¼ 3ê°œì›”(R3M) ë°ì´í„° ë°œê²¬. ì†Œë¹„ ì§‘ì¤‘ë„ ê³„ì‚° ì¤‘...\n",
      "   -> [ìœ„í—˜] í•œë„ ë° ì²­êµ¬ ë°ì´í„° ë°œê²¬. í•œë„ì†Œì§„ìœ¨ ê³„ì‚° ì¤‘...\n",
      "   -> [ìœ„í—˜] ì—°ì²´ ê´€ë ¨ ì»¬ëŸ¼ 22ê°œ ë°œê²¬. ì—°ì²´ ê²½í—˜ í”Œë˜ê·¸ ìƒì„±...\n",
      "   âœ… ìƒì„± ì™„ë£Œ! í˜„ì¬ ì „ì²´ í”¼ì²˜ ìˆ˜: 845ê°œ\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "def create_pattern_and_risk_features(X, X_test, numerical_features, categorical_features):\n",
    "    print(\"ğŸ”„ ì†Œë¹„ íŒ¨í„´ ë° ì‹ ìš© ë¦¬ìŠ¤í¬ íŒŒìƒë³€ìˆ˜ ìƒì„± ì¤‘...\")\n",
    "    \n",
    "    epsilon = 1e-6 # ë‚˜ëˆ—ì…ˆ ì—ëŸ¬ ë°©ì§€ìš©\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 1. ì†Œë¹„ íŒ¨í„´ (Consumption Pattern)\n",
    "    # ---------------------------------------------------------\n",
    "    \n",
    "    # [A] ì˜¨ë¼ì¸ ì†Œë¹„ ë¹„ì¤‘ (ì˜¨ë¼ì¸ ê¸ˆì•¡ / ì´ ê¸ˆì•¡)\n",
    "    # 'ì˜¨ë¼ì¸'ê³¼ 'ê¸ˆì•¡'ì´ ë“¤ì–´ê°„ ì»¬ëŸ¼ ì°¾ê¸°\n",
    "    online_cols = [c for c in X.columns if 'ì˜¨ë¼ì¸' in c and 'ê¸ˆì•¡' in c and '_log1p' not in c]\n",
    "    \n",
    "    if online_cols and 'ì´ì´ìš©ê¸ˆì•¡_R12M' in X.columns:\n",
    "        print(f\"   -> [íŒ¨í„´] ì˜¨ë¼ì¸ ê´€ë ¨ ì»¬ëŸ¼ {len(online_cols)}ê°œ ë°œê²¬. ë¹„ì¤‘ ê³„ì‚° ì¤‘...\")\n",
    "        \n",
    "        # ì˜¨ë¼ì¸ ê¸ˆì•¡ í•©ê³„ (float32)\n",
    "        online_sum = X[online_cols].sum(axis=1).astype('float32')\n",
    "        online_sum_test = X_test[online_cols].sum(axis=1).astype('float32')\n",
    "        \n",
    "        # ë¹„ì¤‘ ê³„ì‚°\n",
    "        X['ì˜¨ë¼ì¸ì†Œë¹„ë¹„ì¤‘'] = (online_sum / (X['ì´ì´ìš©ê¸ˆì•¡_R12M'] + epsilon)).astype('float32')\n",
    "        X_test['ì˜¨ë¼ì¸ì†Œë¹„ë¹„ì¤‘'] = (online_sum_test / (X_test['ì´ì´ìš©ê¸ˆì•¡_R12M'] + epsilon)).astype('float32')\n",
    "        \n",
    "        numerical_features.append('ì˜¨ë¼ì¸ì†Œë¹„ë¹„ì¤‘')\n",
    "    \n",
    "    # [B] ìµœê·¼ ì†Œë¹„ ì§‘ì¤‘ë„ ((R3M * 4) / R12M)\n",
    "    # ìµœê·¼ 3ê°œì›”(R3M) ì´ìš©ê¸ˆì•¡ ì°¾ê¸°\n",
    "    r3m_cols = [c for c in X.columns if 'ì´ìš©ê¸ˆì•¡' in c and 'R3M' in c and '_log1p' not in c]\n",
    "    \n",
    "    if r3m_cols and 'ì´ì´ìš©ê¸ˆì•¡_R12M' in X.columns:\n",
    "        print(f\"   -> [íŒ¨í„´] ìµœê·¼ 3ê°œì›”(R3M) ë°ì´í„° ë°œê²¬. ì†Œë¹„ ì§‘ì¤‘ë„ ê³„ì‚° ì¤‘...\")\n",
    "        \n",
    "        r3m_sum = X[r3m_cols].sum(axis=1).astype('float32')\n",
    "        r3m_sum_test = X_test[r3m_cols].sum(axis=1).astype('float32')\n",
    "        \n",
    "        # ì—°ê°„ í™˜ì‚°(x4) í›„ ë¹„ìœ¨ ê³„ì‚°\n",
    "        X['ìµœê·¼ì†Œë¹„ì§‘ì¤‘ë„'] = ((r3m_sum * 4) / (X['ì´ì´ìš©ê¸ˆì•¡_R12M'] + epsilon)).astype('float32')\n",
    "        X_test['ìµœê·¼ì†Œë¹„ì§‘ì¤‘ë„'] = ((r3m_sum_test * 4) / (X_test['ì´ì´ìš©ê¸ˆì•¡_R12M'] + epsilon)).astype('float32')\n",
    "        \n",
    "        numerical_features.append('ìµœê·¼ì†Œë¹„ì§‘ì¤‘ë„')\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2. ì‹ ìš©ë„ ë° ìœ„í—˜ ê´€ë¦¬ (Risk Management)\n",
    "    # ---------------------------------------------------------\n",
    "\n",
    "    # [C] í•œë„ ì†Œì§„ìœ¨ (ì²­êµ¬ê¸ˆì•¡ / í•œë„ê¸ˆì•¡)\n",
    "    limit_cols = [c for c in X.columns if 'í•œë„' in c and 'ê¸ˆì•¡' in c]\n",
    "    bill_cols = [c for c in X.columns if 'ì²­êµ¬' in c and 'ê¸ˆì•¡' in c]\n",
    "    \n",
    "    if limit_cols and bill_cols:\n",
    "        print(f\"   -> [ìœ„í—˜] í•œë„ ë° ì²­êµ¬ ë°ì´í„° ë°œê²¬. í•œë„ì†Œì§„ìœ¨ ê³„ì‚° ì¤‘...\")\n",
    "        \n",
    "        # ê°€ì¥ ëŒ€í‘œì ì¸ ì»¬ëŸ¼ í•˜ë‚˜ì”©ë§Œ ì‚¬ìš© (ë³´í†µ 0ë²ˆ ì¸ë±ìŠ¤ê°€ ì´í•œë„/ì´ì²­êµ¬)\n",
    "        limit_val = X[limit_cols[0]]\n",
    "        bill_val = X[bill_cols[0]]\n",
    "        \n",
    "        limit_val_test = X_test[limit_cols[0]]\n",
    "        bill_val_test = X_test[bill_cols[0]]\n",
    "        \n",
    "        # ë¹„ìœ¨ ê³„ì‚° ë° ì´ìƒì¹˜ ì œì–´ (1.5ë°° ì´ˆê³¼ ì‹œ 1.5ë¡œ ê³ ì •)\n",
    "        X['í•œë„ì†Œì§„ìœ¨'] = (bill_val / (limit_val + epsilon)).clip(0, 1.5).astype('float32')\n",
    "        X_test['í•œë„ì†Œì§„ìœ¨'] = (bill_val_test / (limit_val_test + epsilon)).clip(0, 1.5).astype('float32')\n",
    "        \n",
    "        numerical_features.append('í•œë„ì†Œì§„ìœ¨')\n",
    "\n",
    "    # [D] ì—°ì²´ ê²½í—˜ ìœ ë¬´ (ì—°ì²´ ì»¬ëŸ¼ í•©ê³„ > 0 ?)\n",
    "    delinq_cols = [c for c in X.columns if 'ì—°ì²´' in c]\n",
    "    \n",
    "    if delinq_cols:\n",
    "        print(f\"   -> [ìœ„í—˜] ì—°ì²´ ê´€ë ¨ ì»¬ëŸ¼ {len(delinq_cols)}ê°œ ë°œê²¬. ì—°ì²´ ê²½í—˜ í”Œë˜ê·¸ ìƒì„±...\")\n",
    "        \n",
    "        # ì—°ì²´ ê¸ˆì•¡ì´ë‚˜ íšŸìˆ˜ê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ 1, ì•„ë‹ˆë©´ 0\n",
    "        X['ì—°ì²´ê²½í—˜ìœ ë¬´'] = (X[delinq_cols].sum(axis=1) > 0).astype('int8')\n",
    "        X_test['ì—°ì²´ê²½í—˜ìœ ë¬´'] = (X_test[delinq_cols].sum(axis=1) > 0).astype('int8')\n",
    "        \n",
    "        if 'ì—°ì²´ê²½í—˜ìœ ë¬´' not in categorical_features:\n",
    "            categorical_features.append('ì—°ì²´ê²½í—˜ìœ ë¬´')\n",
    "\n",
    "    print(f\"   âœ… ìƒì„± ì™„ë£Œ! í˜„ì¬ ì „ì²´ í”¼ì²˜ ìˆ˜: {X.shape[1]}ê°œ\")\n",
    "    gc.collect()\n",
    "    \n",
    "    return X, X_test, numerical_features, categorical_features\n",
    "\n",
    "# ==========================================\n",
    "# ì‹¤í–‰\n",
    "# ==========================================\n",
    "X, X_test, numerical_features, categorical_features = create_pattern_and_risk_features(X, X_test, numerical_features, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6eafe46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ [ì´ˆê³ ì† ëª¨ë“œ] 'ì¹´ë“œì´ìš©í•œë„ê¸ˆì•¡_Aìˆ˜ì¤€ë³µí•©' ë³€ìˆ˜ ìƒì„± ì¤‘...\n",
      "   âœ… 1ì´ˆ ë§Œì— ìƒì„± ì™„ë£Œ! (ê¸°ì¤€ì : 170,344ì›)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def apply_2nd_place_limit_logic_fast(X, X_test):\n",
    "    print(\"ğŸš€ [ì´ˆê³ ì† ëª¨ë“œ] 'ì¹´ë“œì´ìš©í•œë„ê¸ˆì•¡_Aìˆ˜ì¤€ë³µí•©' ë³€ìˆ˜ ìƒì„± ì¤‘...\")\n",
    "    threshold = 170344 \n",
    "    \n",
    "    col_b1 = 'ì¹´ë“œì´ìš©í•œë„ê¸ˆì•¡_B1M'\n",
    "    col_b2 = 'ì¹´ë“œì´ìš©í•œë„ê¸ˆì•¡_B2M'\n",
    "\n",
    "    # .apply ëŒ€ì‹  ë²¡í„° ì—°ì‚° ì‚¬ìš© (True=1, False=0 ì„ì„ ì´ìš©)\n",
    "    # ë‘ ì¡°ê±´ì´ ëª¨ë‘ ì°¸ì´ë©´ 1+1=2, í•˜ë‚˜ë§Œ ì°¸ì´ë©´ 1+0=1, ë‘˜ ë‹¤ ì•„ë‹ˆë©´ 0+0=0ì´ ë©ë‹ˆë‹¤.\n",
    "    X['ì¹´ë“œì´ìš©í•œë„ê¸ˆì•¡_Aìˆ˜ì¤€ë³µí•©'] = (X[col_b1] >= threshold).astype(int) + (X[col_b2] >= threshold).astype(int)\n",
    "    X_test['ì¹´ë“œì´ìš©í•œë„ê¸ˆì•¡_Aìˆ˜ì¤€ë³µí•©'] = (X_test[col_b1] >= threshold).astype(int) + (X_test[col_b2] >= threshold).astype(int)\n",
    "    \n",
    "    # [ê³µì‹ ë“±ë¡] ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€)\n",
    "    if 'ì¹´ë“œì´ìš©í•œë„ê¸ˆì•¡_Aìˆ˜ì¤€ë³µí•©' not in numerical_features:\n",
    "        numerical_features.append('ì¹´ë“œì´ìš©í•œë„ê¸ˆì•¡_Aìˆ˜ì¤€ë³µí•©')\n",
    "        \n",
    "    print(f\"   âœ… 1ì´ˆ ë§Œì— ìƒì„± ì™„ë£Œ! (ê¸°ì¤€ì : {threshold:,.0f}ì›)\")\n",
    "    return X, X_test\n",
    "\n",
    "# ì‹¤í–‰\n",
    "X, X_test = apply_2nd_place_limit_logic_fast(X, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0671deaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ 2ë“± ì†”ë£¨ì…˜ ì•Œê³ ë¦¬ì¦˜ ì ìš©: í•µì‹¬ íŒŒìƒë³€ìˆ˜ 4ì¢… ìë™ ìƒì„± ì¤‘...\n",
      "   ğŸ‘‰ [ì´ìš©ê¸ˆì•¡_ì„ ê²°ì œ_B0M] ë§¤í•‘ ì™„ë£Œ! (ì›ë³¸: ì´ìš©íšŸìˆ˜_ì„ ê²°ì œ_B0M)\n",
      "   ğŸ‘‰ [ì •ìƒì²­êµ¬ì›ê¸ˆ_B5M] ë§¤í•‘ ì™„ë£Œ! (ì›ë³¸: ì •ìƒì²­êµ¬ì›ê¸ˆ_B5M)\n",
      "\n",
      "âœ… ìµœì¢… ì™„ë£Œ. í˜„ì¬ ìˆ˜ì¹˜í˜• í”¼ì²˜ ìˆ˜: 798ê°œ\n",
      "   âœ… ìƒì„± ì™„ë£Œ! í˜„ì¬ ì „ì²´ í”¼ì²˜ ìˆ˜: 846ê°œ\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "print(\"ğŸš€ 2ë“± ì†”ë£¨ì…˜ ì•Œê³ ë¦¬ì¦˜ ì ìš©: í•µì‹¬ íŒŒìƒë³€ìˆ˜ 4ì¢… ìë™ ìƒì„± ì¤‘...\")\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# ğŸ•µï¸â€â™€ï¸ [ì•Œê³ ë¦¬ì¦˜ 1] ìŠ¤ë§ˆíŠ¸ ì»¬ëŸ¼ íƒìƒ‰ê¸° (ì´ë¦„ì´ ë‹¬ë¼ë„ ì°¾ì•„ëƒ…ë‹ˆë‹¤)\n",
    "# --------------------------------------------------------------------------------\n",
    "def find_and_create_avg(df, keywords, term_suffix, new_col_name):\n",
    "    \"\"\"\n",
    "    df: ë°ì´í„°í”„ë ˆì„\n",
    "    keywords: í¬í•¨ë˜ì–´ì•¼ í•  ë‹¨ì–´ë“¤ (ì˜ˆ: ['CA', 'í•´ì™¸'])\n",
    "    term_suffix: ê¸°ê°„ ì ‘ë¯¸ì‚¬ íŒ¨í„´ (ì˜ˆ: ['B1M', 'B2M', 'B3M'])\n",
    "    new_col_name: ë§Œë“¤ ë³€ìˆ˜ ì´ë¦„\n",
    "    \"\"\"\n",
    "    # 1. í‚¤ì›Œë“œê°€ ëª¨ë‘ ë“¤ì–´ê°„ ì»¬ëŸ¼ í›„ë³´ ì°¾ê¸°\n",
    "    candidates = [c for c in df.columns if all(k in c for k in keywords)]\n",
    "    \n",
    "    # 2. ê¸°ê°„(B1M, B2M...)ë³„ë¡œ ë§¤ì¹­ë˜ëŠ” ì»¬ëŸ¼ ì°¾ê¸°\n",
    "    selected_cols = []\n",
    "    found_suffixes = []\n",
    "    \n",
    "    for suffix in term_suffix:\n",
    "        # í›„ë³´ ì¤‘ í•´ë‹¹ ì ‘ë¯¸ì‚¬(ì˜ˆ: B1M)ë¥¼ ê°€ì§„ ë†ˆ ì°¾ê¸°\n",
    "        match = [c for c in candidates if suffix in c]\n",
    "        if match:\n",
    "            selected_cols.append(match[0]) # ì²« ë²ˆì§¸ ë§¤ì¹­ëœ ê²ƒ ì„ íƒ\n",
    "            found_suffixes.append(suffix)\n",
    "            \n",
    "    # 3. í‰ê·  ê³„ì‚° (2ë“± ìŠ¤íƒ€ì¼: ë°ì´í„°ê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ í‰ê·  ëƒ„)\n",
    "    if selected_cols:\n",
    "        print(f\"   ğŸ‘‰ [{new_col_name}] ìƒì„±ì™„ë£Œ! (ì‚¬ìš©ëœ ì›ë³¸: {selected_cols})\")\n",
    "        # fillna(0)ìœ¼ë¡œ ê²°ì¸¡ì¹˜ ë°©ì–´ í›„ í‰ê·  ê³„ì‚°\n",
    "        return df[selected_cols].fillna(0).mean(axis=1)\n",
    "    else:\n",
    "        print(f\"   âš ï¸ [{new_col_name}] ìƒì„± ì‹¤íŒ¨: ê´€ë ¨ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (í‚¤ì›Œë“œ: {keywords})\")\n",
    "        return pd.Series(0, index=df.index)\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# 1ï¸âƒ£ ë³€ìˆ˜ ìƒì„± ì ìš© (Train / Test ëª¨ë‘ ì ìš©)\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "# ì´ìš©ê¸ˆì•¡_ì„ ê²°ì œ_B0M (ì„ ê²°ì œ + ë‹¹ì›”)\n",
    "# ì•Œê³ ë¦¬ì¦˜: 'ì„ ê²°ì œ'ì™€ 'B0M'ì´ ë“¤ì–´ê°„ ì»¬ëŸ¼ì„ ì°¾ì•„ ê·¸ëŒ€ë¡œ ë³µì‚¬\n",
    "prepay_col = [c for c in X.columns if 'ì„ ê²°ì œ' in c and 'B0M' in c]\n",
    "if prepay_col:\n",
    "    col_name = prepay_col[0]\n",
    "    X['ì´ìš©ê¸ˆì•¡_ì„ ê²°ì œ_B0M'] = X[col_name].fillna(0)\n",
    "    X_test['ì´ìš©ê¸ˆì•¡_ì„ ê²°ì œ_B0M'] = X_test[col_name].fillna(0)\n",
    "    print(f\"   ğŸ‘‰ [ì´ìš©ê¸ˆì•¡_ì„ ê²°ì œ_B0M] ë§¤í•‘ ì™„ë£Œ! (ì›ë³¸: {col_name})\")\n",
    "else:\n",
    "    X['ì´ìš©ê¸ˆì•¡_ì„ ê²°ì œ_B0M'] = 0\n",
    "    X_test['ì´ìš©ê¸ˆì•¡_ì„ ê²°ì œ_B0M'] = 0\n",
    "    print(\"   âš ï¸ [ì´ìš©ê¸ˆì•¡_ì„ ê²°ì œ_B0M] ê´€ë ¨ ì»¬ëŸ¼ ì—†ìŒ -> 0ìœ¼ë¡œ ì±„ì›€\")\n",
    "\n",
    "#  ì •ìƒì²­êµ¬ì›ê¸ˆ_B5M\n",
    "# 'ì •ìƒ' + 'ì²­êµ¬' + 'B5M' í‚¤ì›Œë“œ\n",
    "normal_bill_col = [c for c in X.columns if 'ì •ìƒ' in c and 'ì²­êµ¬' in c and 'B5M' in c]\n",
    "if normal_bill_col:\n",
    "    X['ì •ìƒì²­êµ¬ì›ê¸ˆ_B5M'] = X[normal_bill_col[0]].fillna(0)\n",
    "    X_test['ì •ìƒì²­êµ¬ì›ê¸ˆ_B5M'] = X_test[normal_bill_col[0]].fillna(0)\n",
    "    print(f\"   ğŸ‘‰ [ì •ìƒì²­êµ¬ì›ê¸ˆ_B5M] ë§¤í•‘ ì™„ë£Œ! (ì›ë³¸: {normal_bill_col[0]})\")\n",
    "else:\n",
    "    X['ì •ìƒì²­êµ¬ì›ê¸ˆ_B5M'] = 0\n",
    "    X_test['ì •ìƒì²­êµ¬ì›ê¸ˆ_B5M'] = 0\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# 2ï¸âƒ£ ë¦¬ìŠ¤íŠ¸ ë“±ë¡ ë° ì •ë¦¬ (í•„ìˆ˜!)\n",
    "# --------------------------------------------------------------------------------\n",
    "new_features = ['í‰ì”_CA_í•´ì™¸_3M', 'ì´ìš©ê¸ˆì•¡_ì„ ê²°ì œ_B0M', 'í• ë¶€ê¸ˆì•¡_ë¬´ì´ì_3M_R12M', 'ì •ìƒì²­êµ¬ì›ê¸ˆ_B5M']\n",
    "\n",
    "for col in new_features:\n",
    "    if col not in numerical_features:\n",
    "        numerical_features.append(col)\n",
    "\n",
    "# ì¤‘ë³µ ì œê±°\n",
    "numerical_features = list(dict.fromkeys(numerical_features))\n",
    "categorical_features = list(dict.fromkeys(categorical_features))\n",
    "\n",
    "print(f\"\\nâœ… ìµœì¢… ì™„ë£Œ. í˜„ì¬ ìˆ˜ì¹˜í˜• í”¼ì²˜ ìˆ˜: {len(numerical_features)}ê°œ\")\n",
    "gc.collect()\n",
    "\n",
    "print(f\"   âœ… ìƒì„± ì™„ë£Œ! í˜„ì¬ ì „ì²´ í”¼ì²˜ ìˆ˜: {X.shape[1]}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63ec92a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì¤‘ë³µ ì œê±° ì™„ë£Œ! í˜„ì¬ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ê°œìˆ˜: 798ê°œ\n",
      "âœ… ë°ì´í„°í”„ë ˆì„ ì»¬ëŸ¼ ì¤‘ë³µ ì œê±° ì™„ë£Œ.\n"
     ]
    }
   ],
   "source": [
    "# 1. ì¤‘ë³µëœ ì´ë¦„í‘œ ì‹¹ ì •ë¦¬í•˜ê¸° (ìˆœì„œ ìœ ì§€í•˜ë©° ì¤‘ë³µ ì œê±°)\n",
    "numerical_features = list(dict.fromkeys(numerical_features))\n",
    "categorical_features = list(dict.fromkeys(categorical_features))\n",
    "\n",
    "print(f\"âœ… ì¤‘ë³µ ì œê±° ì™„ë£Œ! í˜„ì¬ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ê°œìˆ˜: {len(numerical_features)}ê°œ\")\n",
    "\n",
    "# 2. í˜¹ì‹œ ëª¨ë¥´ë‹ˆ ë°ì´í„°(X)ì— ì¤‘ë³µëœ ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ë„ í™•ì¸ (ìˆìœ¼ë©´ ì œê±°)\n",
    "X = X.loc[:, ~X.columns.duplicated()].copy()\n",
    "X_test = X_test.loc[:, ~X_test.columns.duplicated()].copy()\n",
    "\n",
    "print(\"âœ… ë°ì´í„°í”„ë ˆì„ ì»¬ëŸ¼ ì¤‘ë³µ ì œê±° ì™„ë£Œ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc8bbc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ (6) í´ëŸ¬ìŠ¤í„°ë§ ë° (7) ìµœì¢… ì •ë¦¬ ì‹œì‘...\n",
      "   -> í´ëŸ¬ìŠ¤í„°ë§ í•™ìŠµ ì¤‘ (ëŒ€ìƒ ë³€ìˆ˜ 208ê°œ)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\CY2\\miniconda3\\envs\\DS\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\CY2\\miniconda3\\envs\\DS\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\CY2\\miniconda3\\envs\\DS\\Lib\\subprocess.py\", line 1599, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"<frozen codecs>\", line 322, in decode\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc0 in position 4: invalid start byte\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… ì™„ë£Œ. ìµœì¢… ì»¬ëŸ¼ ìˆ˜: 847\n",
      "ğŸ”„ (6) í´ëŸ¬ìŠ¤í„°ë§ ë° (7) ìµœì¢… ì •ë¦¬ ì‹œì‘...\n",
      "   âœ… ì™„ë£Œ. ìµœì¢… ì»¬ëŸ¼ ìˆ˜: 847\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import gc\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =========================================================\n",
    "# âœ… Step 3-6 & 7: í´ëŸ¬ìŠ¤í„°ë§ ë° ìµœì¢… ì •ë¦¬ í•¨ìˆ˜\n",
    "# =========================================================\n",
    "def apply_clustering_and_cleanup(df, numerical_features, categorical_features, fit_objects=None):\n",
    "    print(\"ğŸ”„ (6) í´ëŸ¬ìŠ¤í„°ë§ ë° (7) ìµœì¢… ì •ë¦¬ ì‹œì‘...\")\n",
    "    \n",
    "    # 1. ë³€ìˆ˜ ì´ˆê¸°í™” ë° ì„¤ì •\n",
    "    X_eng = df.copy() # ì›ë³¸ ë³´ì¡´ì„ ìœ„í•´ ë³µì‚¬\n",
    "    current_num_features = numerical_features[:]\n",
    "    current_cat_features = categorical_features[:]\n",
    "    \n",
    "    RANDOM_STATE = 42\n",
    "    \n",
    "    # í•™ìŠµ ëª¨ë“œ í™•ì¸\n",
    "    is_training = (fit_objects is None)\n",
    "    if is_training: fit_objects = {}\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # (6) í´ëŸ¬ìŠ¤í„°ë§ (MiniBatchKMeans)\n",
    "    # ---------------------------------------------------------\n",
    "    # ë¡œê·¸ ë³€í™˜ëœ ì»¬ëŸ¼ë“¤ë§Œ ì°¾ê¸°\n",
    "    cluster_cols_log = [col for col in current_num_features if '_log1p' in col and col in X_eng.columns]\n",
    "    \n",
    "    # í”¼ì²˜ê°€ 2ê°œ ì´ìƒì´ì–´ì•¼ í´ëŸ¬ìŠ¤í„°ë§ ê°€ëŠ¥\n",
    "    if len(cluster_cols_log) >= 2:\n",
    "        if is_training:\n",
    "            print(f\"   -> í´ëŸ¬ìŠ¤í„°ë§ í•™ìŠµ ì¤‘ (ëŒ€ìƒ ë³€ìˆ˜ {len(cluster_cols_log)}ê°œ)...\")\n",
    "            \n",
    "            # (A) ë¶„í¬ ë³€í™˜ (QuantileTransformer)\n",
    "            qt = QuantileTransformer(output_distribution='normal', random_state=RANDOM_STATE)\n",
    "            \n",
    "            # ë©”ëª¨ë¦¬ ë³´í˜¸: 10ë§Œ ê°œë§Œ ìƒ˜í”Œë§í•´ì„œ í•™ìŠµ (fit)\n",
    "            sample_size = min(100000, len(X_eng))\n",
    "            sample_idx = X_eng[cluster_cols_log].sample(n=sample_size, random_state=RANDOM_STATE).index\n",
    "            \n",
    "            # ìƒ˜í”Œ ë°ì´í„°ë¡œ fit\n",
    "            qt.fit(X_eng.loc[sample_idx, cluster_cols_log].fillna(0))\n",
    "            \n",
    "            # (B) í´ëŸ¬ìŠ¤í„°ë§ í•™ìŠµ (MiniBatchKMeans)\n",
    "            kmeans = MiniBatchKMeans(n_clusters=5, random_state=RANDOM_STATE, batch_size=4096, n_init=3)\n",
    "            \n",
    "            # ì „ì²´ ë°ì´í„° ë³€í™˜ (Transform)\n",
    "            X_scaled = qt.transform(X_eng[cluster_cols_log].fillna(0))\n",
    "            \n",
    "            # ì˜ˆì¸¡ ë° int8 ë³€í™˜\n",
    "            X_eng['cluster_feature'] = kmeans.fit_predict(X_scaled).astype('int8')\n",
    "            \n",
    "            # ê°ì²´ ì €ì¥ (Test ì ìš©ì„ ìœ„í•´)\n",
    "            fit_objects['kmeans'] = kmeans\n",
    "            fit_objects['qt_cluster'] = qt\n",
    "            fit_objects['cluster_cols_log'] = cluster_cols_log\n",
    "            \n",
    "        else:\n",
    "            # Test ëª¨ë“œ: ì €ì¥ëœ ê°ì²´ê°€ ìˆì„ ë•Œë§Œ ì‹¤í–‰\n",
    "            if 'kmeans' in fit_objects and 'qt_cluster' in fit_objects:\n",
    "                qt = fit_objects['qt_cluster']\n",
    "                kmeans = fit_objects['kmeans']\n",
    "                cols = fit_objects['cluster_cols_log']\n",
    "                \n",
    "                # Test ë°ì´í„°ì— í•´ë‹¹ ì»¬ëŸ¼ì´ ë‹¤ ìˆëŠ”ì§€ í™•ì¸\n",
    "                cols = [c for c in cols if c in X_eng.columns]\n",
    "                \n",
    "                if len(cols) > 0:\n",
    "                    # ì—†ëŠ” ì»¬ëŸ¼ì€ 0ìœ¼ë¡œ ì±„ìš°ëŠ” ì•ˆì „ì¥ì¹˜ (í•„ìš”ì‹œ)\n",
    "                    # ì—¬ê¸°ì„  ìˆëŠ” ê²ƒë§Œ ê°€ì§€ê³  transform ì‹œë„ (ì°¨ì› ì£¼ì˜)\n",
    "                    try:\n",
    "                        X_scaled = qt.transform(X_eng[cols].fillna(0))\n",
    "                        X_eng['cluster_feature'] = kmeans.predict(X_scaled).astype('int8')\n",
    "                    except ValueError:\n",
    "                        print(\"   âš ï¸ ê²½ê³ : Test ë°ì´í„° ì°¨ì› ë¶ˆì¼ì¹˜ë¡œ í´ëŸ¬ìŠ¤í„°ë§ 0 ì²˜ë¦¬\")\n",
    "                        X_eng['cluster_feature'] = 0\n",
    "                else:\n",
    "                    X_eng['cluster_feature'] = 0\n",
    "            else:\n",
    "                X_eng['cluster_feature'] = 0\n",
    "        \n",
    "        # ë²”ì£¼í˜• ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "        if 'cluster_feature' not in current_cat_features: \n",
    "            current_cat_features.append('cluster_feature')\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # (7) ìµœì¢… ì •ë¦¬ ë° ì•ˆì •ì„± í™•ì¸\n",
    "    # ---------------------------------------------------------\n",
    "    # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ë‚¨ê¸°ê³  ì •ë ¬\n",
    "    final_num = sorted(list(set([f for f in current_num_features if f in X_eng.columns])))\n",
    "    final_cat = sorted(list(set([f for f in current_cat_features if f in X_eng.columns])))\n",
    "    \n",
    "    # ë®ì–´ì“°ê¸° (ë©”ëª¨ë¦¬ ì •ë¦¬)\n",
    "    X_eng = X_eng[final_num + final_cat].copy()\n",
    "\n",
    "    # NaN/Inf ì²˜ë¦¬ (ìˆ˜ì¹˜í˜•ë§Œ)\n",
    "    X_eng[final_num] = X_eng[final_num].replace([np.inf, -np.inf], 0).fillna(0).astype('float32')\n",
    "    \n",
    "    gc.collect()\n",
    "    print(f\"   âœ… ì™„ë£Œ. ìµœì¢… ì»¬ëŸ¼ ìˆ˜: {X_eng.shape[1]}\")\n",
    "    \n",
    "    return X_eng, final_num, final_cat, fit_objects\n",
    "\n",
    "# =========================================================\n",
    "# ğŸš€ ì‹¤í–‰ ì½”ë“œ (Train -> Test)\n",
    "# =========================================================\n",
    "\n",
    "# 1. Train ì ìš©\n",
    "# (X, numerical_features, categorical_featuresëŠ” ì´ë¯¸ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•¨)\n",
    "X, numerical_features, categorical_features, fit_objects = apply_clustering_and_cleanup(\n",
    "    X, numerical_features, categorical_features, fit_objects=None\n",
    ")\n",
    "\n",
    "# 2. Test ì ìš© (fit_objects ì „ë‹¬ í•„ìˆ˜)\n",
    "X_test, _, _, _ = apply_clustering_and_cleanup(\n",
    "    X_test, numerical_features, categorical_features, fit_objects=fit_objects\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d57378a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ í´ëŸ¬ìŠ¤í„°ë§ ë° ìµœì¢… ì •ë¦¬ í•¨ìˆ˜ ì ìš© ì¤‘...\n",
      "ğŸ”„ (6) í´ëŸ¬ìŠ¤í„°ë§ ë° (7) ìµœì¢… ì •ë¦¬ ì‹œì‘...\n",
      "   -> í´ëŸ¬ìŠ¤í„°ë§ í•™ìŠµ ì¤‘ (ëŒ€ìƒ ë³€ìˆ˜ 208ê°œ)...\n",
      "   âœ… ì™„ë£Œ. ìµœì¢… ì»¬ëŸ¼ ìˆ˜: 847\n",
      "ğŸ”„ (6) í´ëŸ¬ìŠ¤í„°ë§ ë° (7) ìµœì¢… ì •ë¦¬ ì‹œì‘...\n",
      "   âœ… ì™„ë£Œ. ìµœì¢… ì»¬ëŸ¼ ìˆ˜: 847\n",
      "\n",
      "âœ¨ ì „ì²˜ë¦¬ ì™„ë£Œ! ë°ì´í„°ê°€ ìµœì¢… í™•ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "   - ìµœì¢… Train í¬ê¸°: (2400000, 847)\n",
      "   - ìµœì¢… Test í¬ê¸°: (600000, 847)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "print(\"ğŸš€ í´ëŸ¬ìŠ¤í„°ë§ ë° ìµœì¢… ì •ë¦¬ í•¨ìˆ˜ ì ìš© ì¤‘...\")\n",
    "\n",
    "# 1. Train ë°ì´í„° ì ìš© (fit_objects ìƒì„±)\n",
    "X, numerical_features, categorical_features, fit_objects = apply_clustering_and_cleanup(\n",
    "    X, numerical_features, categorical_features, fit_objects=None\n",
    ")\n",
    "\n",
    "# 2. Test ë°ì´í„° ì ìš© (ìƒì„±ëœ fit_objects ì‚¬ìš©)\n",
    "X_test, _, _, _ = apply_clustering_and_cleanup(\n",
    "    X_test, numerical_features, categorical_features, fit_objects=fit_objects\n",
    ")\n",
    "\n",
    "# 3. ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "gc.collect()\n",
    "\n",
    "print(\"\\nâœ¨ ì „ì²˜ë¦¬ ì™„ë£Œ! ë°ì´í„°ê°€ ìµœì¢… í™•ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "print(f\"   - ìµœì¢… Train í¬ê¸°: {X.shape}\")\n",
    "print(f\"   - ìµœì¢… Test í¬ê¸°: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35e4960a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ Step 5: í”¼ì²˜ ì„ íƒ(Feature Selection) ì‹œì‘... (ì›ë³¸ ë³´ì¡´ ëª¨ë“œ)\n",
      "   - í”¼ì²˜ ì„ íƒìš© ì„ì‹œ ì¸ì½”ë”© ì™„ë£Œ (48ê°œ).\n",
      "âŒ Step 5 ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: Unable to allocate 15.1 GiB for an array with shape (2400000, 847) and data type float64\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "\n",
    "print(\"\\nğŸ”„ Step 5: í”¼ì²˜ ì„ íƒ(Feature Selection) ì‹œì‘... (ì›ë³¸ ë³´ì¡´ ëª¨ë“œ)\")\n",
    "start_time_step5 = time.time()\n",
    "\n",
    "try:\n",
    "    # 1. í”¼ì²˜ ì„ íƒì„ ìœ„í•œ ì„ì‹œ ë°ì´í„° ìƒì„± (ì›ë³¸ X ë³µì‚¬)\n",
    "    X_temp_fs = X.copy()\n",
    "    \n",
    "    # 2. ë²”ì£¼í˜• ë³€ìˆ˜ ì„ì‹œ ë¼ë²¨ ì¸ì½”ë”©\n",
    "    cat_features_for_fs = X_temp_fs.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    for col in cat_features_for_fs:\n",
    "        le_fs = LabelEncoder()\n",
    "        X_temp_fs[col] = le_fs.fit_transform(X_temp_fs[col].astype(str))\n",
    "    \n",
    "    print(f\"   - í”¼ì²˜ ì„ íƒìš© ì„ì‹œ ì¸ì½”ë”© ì™„ë£Œ ({len(cat_features_for_fs)}ê°œ).\")\n",
    "\n",
    "    # 3. LightGBMì„ ì´ìš©í•œ í”¼ì²˜ ì¤‘ìš”ë„ ê³„ì‚°\n",
    "    lgbm_selector = lgb.LGBMClassifier(\n",
    "        n_estimators=100, random_state=42, objective='multiclass', \n",
    "        metric='multi_logloss', n_jobs=-1, force_col_wise=True\n",
    "    )\n",
    "    lgbm_selector.fit(X_temp_fs, y_encoded)\n",
    "\n",
    "    # 4. ì¤‘ìš”ë„ ìƒìœ„ 400ê°œ í”¼ì²˜ ì„ íƒ (ì¤‘ì•™ê°’ ëŒ€ì‹  ì•ˆì •ì ì¸ ê°œìˆ˜ ì„ íƒ)\n",
    "    importances = lgbm_selector.feature_importances_\n",
    "    feat_imp_df = pd.DataFrame({'feature': X_temp_fs.columns, 'importance': importances})\n",
    "    feat_imp_df = feat_imp_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "    selected_feature_names = feat_imp_df.head(400)['feature'].tolist()\n",
    "\n",
    "    print(f\"   - í”¼ì²˜ ì„ íƒ ì™„ë£Œ. (850ê°œ ë‚´ì™¸ -> {len(selected_feature_names)}ê°œ ì¶”ì¶œ)\")\n",
    "\n",
    "    # 5. â­ [í•µì‹¬ ë³€ê²½] ì›ë³¸ X, X_testëŠ” ê±´ë“œë¦¬ì§€ ì•Šê³  'í•™ìŠµ ì „ìš© ë³€ìˆ˜' ìƒì„±\n",
    "    X_train_fs = X[selected_feature_names].copy()\n",
    "    X_test_fs = X_test[selected_feature_names].copy()\n",
    "\n",
    "    # í•™ìŠµìš© ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ (ì›ë³¸ ë¦¬ìŠ¤íŠ¸ì™€ ë³„ê°œë¡œ ê´€ë¦¬)\n",
    "    num_fs = X_train_fs.select_dtypes(include=np.number).columns.tolist()\n",
    "    cat_fs = X_train_fs.select_dtypes(exclude=np.number).columns.tolist()\n",
    "    \n",
    "    print(f\"   - âœ… í•™ìŠµìš© ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: ìˆ˜ì¹˜í˜• {len(num_fs)}ê°œ, ë²”ì£¼í˜• {len(cat_fs)}ê°œ\")\n",
    "    print(\"   âš ï¸ ì£¼ì˜: ì•„ë˜ í•™ìŠµ ì…€(Optuna ë“±)ì—ì„œ X ëŒ€ì‹  'X_train_fs'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”!\")\n",
    "\n",
    "    # 6. ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "    del X_temp_fs, lgbm_selector, feat_imp_df\n",
    "    gc.collect()\n",
    "    \n",
    "    end_time_step5 = time.time()\n",
    "    print(f\"âœ… Step 5 ì™„ë£Œ. (ì†Œìš” ì‹œê°„: {end_time_step5 - start_time_step5:.2f} ì´ˆ)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Step 5 ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f08b689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª [ëª¨ë“œ] íŒŒìƒë³€ìˆ˜ ì‹¤í—˜ ëª¨ë“œ (5% ìƒ˜í”Œë§)\n",
      "ğŸš€ Optuna ì‹œì‘! (Mode: FEATURE_TEST, Sample: 5.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-06 17:47:16,296] A new study created in memory with name: no-name-10c5ec15-e0bf-42d1-a23a-f1fe5db0120d\n",
      "[I 2026-02-06 17:47:16,337] Trial 0 finished with value: 0.0 and parameters: {}. Best is trial 0 with value: 0.0.\n",
      "[I 2026-02-06 17:47:16,339] Trial 1 finished with value: 0.0 and parameters: {}. Best is trial 0 with value: 0.0.\n",
      "[I 2026-02-06 17:47:16,345] Trial 2 finished with value: 0.0 and parameters: {}. Best is trial 0 with value: 0.0.\n",
      "[I 2026-02-06 17:47:16,366] Trial 3 finished with value: 0.0 and parameters: {}. Best is trial 0 with value: 0.0.\n",
      "[I 2026-02-06 17:47:16,384] Trial 4 finished with value: 0.0 and parameters: {}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Sampling Error: name 'X_train_fs' is not defined\n",
      "âŒ Sampling Error: name 'X_train_fs' is not defined\n",
      "âŒ Sampling Error: name 'X_train_fs' is not defined\n",
      "âŒ Sampling Error: name 'X_train_fs' is not defined\n",
      "âŒ Sampling Error: name 'X_train_fs' is not defined\n",
      "\n",
      "ğŸ† [ê²°ê³¼] ìµœì  íŒŒë¼ë¯¸í„°: {}\n",
      "ğŸ† [ê²°ê³¼] ìµœê³  ì ìˆ˜: 0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import category_encoders as ce\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import gc\n",
    "import time\n",
    "import optuna\n",
    "\n",
    "# =============================================================================\n",
    "# ğŸ›ï¸ [ì»¨íŠ¸ë¡¤ íƒ€ì›Œ] ì—¬ê¸°ë§Œ ë°”ê¾¸ë©´ ì•Œì•„ì„œ ë³€ì‹ í•©ë‹ˆë‹¤!\n",
    "# =============================================================================\n",
    "MODE = 'FEATURE_TEST'  # ğŸ‘‰ 'FEATURE_TEST' ë˜ëŠ” 'PARAM_TUNING' ì¤‘ ì„ íƒ\n",
    "\n",
    "if MODE == 'FEATURE_TEST':\n",
    "    print(\"ğŸ§ª [ëª¨ë“œ] íŒŒìƒë³€ìˆ˜ ì‹¤í—˜ ëª¨ë“œ (5% ìƒ˜í”Œë§)\")\n",
    "    SAMPLE_FRAC = 0.05    # 5%ë§Œ ì‚¬ìš© (ì†ë„ ê·¹ëŒ€í™”)\n",
    "    N_TRIALS = 5          # 5ë²ˆë§Œ ëŒ€ì¶© ëŒë ¤ë³´ê³  ì ìˆ˜ ì˜¤ë¥´ëŠ”ì§€ í™•ì¸\n",
    "    N_FOLDS = 3           # Foldë„ 3ê°œë§Œ (ë¹ ë¥´ê²Œ)\n",
    "    \n",
    "elif MODE == 'PARAM_TUNING':\n",
    "    print(\"ğŸšï¸ [ëª¨ë“œ] íŒŒë¼ë¯¸í„° ì •ë°€ íŠœë‹ ëª¨ë“œ (20% ìƒ˜í”Œë§)\")\n",
    "    SAMPLE_FRAC = 0.2     # 20% ì‚¬ìš© (ì‹ ë¢°ë„ í™•ë³´)\n",
    "    N_TRIALS = 50         # 50ë²ˆ ëŒë ¤ì„œ ì§„ì§œ ìµœì ê°’ ì°¾ê¸°\n",
    "    N_FOLDS = 5           # Fold 5ê°œ (êµ­ë£°)\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "def objective(trial):\n",
    "    # --- 1. ë°ì´í„° ìƒ˜í”Œë§ ---\n",
    "    # ì „ì—­ ë³€ìˆ˜ SAMPLE_FRACì„ ì‚¬ìš©\n",
    "    try:\n",
    "        # XëŠ” ì‚¬ìš©ìë‹˜ ì½”ë“œì—ì„œ ì •ì˜ëœ ì „ì²´ ë°ì´í„°ì…‹ ë³€ìˆ˜ëª…\n",
    "        _, X_sample, _, y_sample = train_test_split(\n",
    "            X_train_fs, y_encoded, test_size=SAMPLE_FRAC,\n",
    "            random_state=42 + trial.number, stratify=y_encoded\n",
    "        )\n",
    "        X_sample = X_sample.reset_index(drop=True)\n",
    "        # y_sampleì€ numpy arrayì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ hasattr ì²´í¬\n",
    "        if hasattr(y_sample, 'reset_index'):\n",
    "            y_sample = y_sample.reset_index(drop=True)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Sampling Error: {e}\")\n",
    "        return 0.0\n",
    "    \n",
    "    gc.collect()\n",
    "\n",
    "    # --- 2. íŒŒë¼ë¯¸í„° íƒìƒ‰ ë²”ìœ„ ---\n",
    "    params = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': num_classes, # ë¯¸ë¦¬ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•¨\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'tree_method': 'hist',\n",
    "        'device': 'cuda',         # GPU ì‚¬ìš©\n",
    "        'random_state': 42,\n",
    "        'nthread': -1,\n",
    "        \n",
    "        # íŠœë‹í•  í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "        'eta': trial.suggest_float('eta', 0.01, 0.1, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 0.0, 5.0),\n",
    "        'lambda': trial.suggest_float('lambda', 0.1, 100.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 0.0, 10.0),\n",
    "    }\n",
    "\n",
    "    # --- 3. í•™ìŠµ ë° ê²€ì¦ ---\n",
    "    oof_preds_proba = np.zeros((len(X_sample), num_classes))\n",
    "    oof_labels = np.zeros(len(X_sample))\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "    cat_cols = X_sample.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    start_trial = time.time()\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_sample, y_sample)):\n",
    "        X_train_fold, X_val_fold = X_sample.iloc[train_idx].copy(), X_sample.iloc[val_idx].copy()\n",
    "        y_train_fold, y_val_fold = y_sample[train_idx], y_sample[val_idx]\n",
    "\n",
    "        # (1) Target Encoding\n",
    "        if cat_cols:\n",
    "            try:\n",
    "                te = ce.TargetEncoder(cols=cat_cols, handle_missing='value', handle_unknown='value', smoothing=1.0)\n",
    "                X_train_fold = te.fit_transform(X_train_fold, y_train_fold)\n",
    "                X_val_fold = te.transform(X_val_fold)\n",
    "            except: pass\n",
    "\n",
    "        # (2) SMOTE\n",
    "        try:\n",
    "            smote = SMOTE(random_state=42 + fold, k_neighbors=5)\n",
    "            X_train_resampled, y_train_resampled = smote.fit_resample(X_train_fold, y_train_fold)\n",
    "        except:\n",
    "            X_train_resampled, y_train_resampled = X_train_fold, y_train_fold\n",
    "\n",
    "        X_train_resampled = X_train_resampled.astype(np.float32)\n",
    "        X_val_fold = X_val_fold.astype(np.float32)\n",
    "\n",
    "        # (3) XGBoost Train\n",
    "        dtrain = xgb.DMatrix(X_train_resampled, label=y_train_resampled)\n",
    "        dval = xgb.DMatrix(X_val_fold, label=y_val_fold)\n",
    "        \n",
    "        # Feature Test ëª¨ë“œì¼ ë•ŒëŠ” í•™ìŠµ ë¼ìš´ë“œë¥¼ ì¤„ì—¬ì„œ ì†ë„ í–¥ìƒ\n",
    "        boost_rounds = 200 if MODE == 'FEATURE_TEST' else 500\n",
    "        \n",
    "        booster = xgb.train(\n",
    "            params=params, dtrain=dtrain, num_boost_round=boost_rounds,\n",
    "            evals=[(dval, 'eval')], early_stopping_rounds=30,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "\n",
    "        val_preds = booster.predict(dval, iteration_range=(0, booster.best_iteration))\n",
    "        oof_preds_proba[val_idx] = val_preds\n",
    "        oof_labels[val_idx] = y_val_fold\n",
    "        \n",
    "        del X_train_fold, X_val_fold, dtrain, dval, booster; gc.collect()\n",
    "\n",
    "    # --- 4. ê²°ê³¼ ì§‘ê³„ ---\n",
    "    final_preds = np.argmax(oof_preds_proba, axis=1)\n",
    "    macro_f1 = f1_score(oof_labels, final_preds, average='macro', zero_division=0)\n",
    "    \n",
    "    elapsed = time.time() - start_trial\n",
    "    print(f\"   [Trial {trial.number}] F1 Score: {macro_f1:.4f} (Time: {elapsed:.1f}s)\")\n",
    "    \n",
    "    return macro_f1\n",
    "\n",
    "# ğŸ† ì‹¤í–‰\n",
    "print(f\"ğŸš€ Optuna ì‹œì‘! (Mode: {MODE}, Sample: {SAMPLE_FRAC*100}%)\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=N_TRIALS)\n",
    "\n",
    "print(\"\\nğŸ† [ê²°ê³¼] ìµœì  íŒŒë¼ë¯¸í„°:\", study.best_params)\n",
    "print(\"ğŸ† [ê²°ê³¼] ìµœê³  ì ìˆ˜:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12827b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-06 11:33:58,346] A new study created in memory with name: no-name-3f98a0ce-259d-4695-b628-1d1bafc4f79b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Optuna ìµœì í™” ì‹œì‘ (ë¡œê·¸ ì¶œë ¥ ëª¨ë“œ)...\n",
      "\n",
      "ğŸš€ [Trial 0] ì‹œì‘! (ë°ì´í„° ìƒ˜í”Œë§ ì¤‘...)\n",
      "   Current Fold: 1/3... âœ… Done.\n",
      "   Current Fold: 2/3... âœ… Done.\n",
      "   Current Fold: 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-06 11:35:30,181] Trial 0 finished with value: 0.4616319921851906 and parameters: {'eta': 0.05101828393625498, 'max_depth': 9, 'subsample': 0.736709985014893, 'colsample_bytree': 0.833797859056018, 'min_child_weight': 10, 'gamma': 3.986697747660632, 'lambda': 0.39255232615091845, 'alpha': 1.3779633633402721}. Best is trial 0 with value: 0.4616319921851906.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done.\n",
      "   -> Trial 0 ì™„ë£Œ! Score: 0.4616 (ì†Œìš”ì‹œê°„: 91.8ì´ˆ)\n",
      "\n",
      "ğŸš€ [Trial 1] ì‹œì‘! (ë°ì´í„° ìƒ˜í”Œë§ ì¤‘...)\n",
      "   Current Fold: 1/3... âœ… Done.\n",
      "   Current Fold: 2/3... âœ… Done.\n",
      "   Current Fold: 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-06 11:36:54,066] Trial 1 finished with value: 0.457117478209795 and parameters: {'eta': 0.04240585890226002, 'max_depth': 10, 'subsample': 0.7806578065218979, 'colsample_bytree': 0.9161337182060387, 'min_child_weight': 3, 'gamma': 4.859801889678062, 'lambda': 36.41054180189917, 'alpha': 1.5202325861847155}. Best is trial 0 with value: 0.4616319921851906.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done.\n",
      "   -> Trial 1 ì™„ë£Œ! Score: 0.4571 (ì†Œìš”ì‹œê°„: 83.8ì´ˆ)\n",
      "\n",
      "ğŸš€ [Trial 2] ì‹œì‘! (ë°ì´í„° ìƒ˜í”Œë§ ì¤‘...)\n",
      "   Current Fold: 1/3... âœ… Done.\n",
      "   Current Fold: 2/3... âœ… Done.\n",
      "   Current Fold: 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-06 11:38:14,959] Trial 2 finished with value: 0.44976918359443435 and parameters: {'eta': 0.022815697879022354, 'max_depth': 6, 'subsample': 0.9649868134965626, 'colsample_bytree': 0.6436395048905377, 'min_child_weight': 4, 'gamma': 3.2570237004672613, 'lambda': 1.4623985386946672, 'alpha': 2.153365878561887}. Best is trial 0 with value: 0.4616319921851906.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done.\n",
      "   -> Trial 2 ì™„ë£Œ! Score: 0.4498 (ì†Œìš”ì‹œê°„: 80.9ì´ˆ)\n",
      "\n",
      "ğŸš€ [Trial 3] ì‹œì‘! (ë°ì´í„° ìƒ˜í”Œë§ ì¤‘...)\n",
      "   Current Fold: 1/3... âœ… Done.\n",
      "   Current Fold: 2/3... âœ… Done.\n",
      "   Current Fold: 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-06 11:39:26,511] Trial 3 finished with value: 0.4607664439760818 and parameters: {'eta': 0.07395910345070954, 'max_depth': 6, 'subsample': 0.8151837531541205, 'colsample_bytree': 0.9002205354730581, 'min_child_weight': 5, 'gamma': 3.8812763372387638, 'lambda': 52.20028215554422, 'alpha': 8.814980229619534}. Best is trial 0 with value: 0.4616319921851906.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done.\n",
      "   -> Trial 3 ì™„ë£Œ! Score: 0.4608 (ì†Œìš”ì‹œê°„: 71.5ì´ˆ)\n",
      "\n",
      "ğŸš€ [Trial 4] ì‹œì‘! (ë°ì´í„° ìƒ˜í”Œë§ ì¤‘...)\n",
      "   Current Fold: 1/3... âœ… Done.\n",
      "   Current Fold: 2/3... âœ… Done.\n",
      "   Current Fold: 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-06 11:41:18,721] Trial 4 finished with value: 0.47710670459633614 and parameters: {'eta': 0.02246475999856469, 'max_depth': 10, 'subsample': 0.922526788357882, 'colsample_bytree': 0.6360158085153711, 'min_child_weight': 5, 'gamma': 4.008137524489415, 'lambda': 0.2852375151549684, 'alpha': 0.59059736533698}. Best is trial 4 with value: 0.47710670459633614.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done.\n",
      "   -> Trial 4 ì™„ë£Œ! Score: 0.4771 (ì†Œìš”ì‹œê°„: 112.2ì´ˆ)\n",
      "\n",
      "ğŸš€ [Trial 5] ì‹œì‘! (ë°ì´í„° ìƒ˜í”Œë§ ì¤‘...)\n",
      "   Current Fold: 1/3... âœ… Done.\n",
      "   Current Fold: 2/3... âœ… Done.\n",
      "   Current Fold: 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-06 11:42:41,734] Trial 5 finished with value: 0.5250283406873293 and parameters: {'eta': 0.0726332393055898, 'max_depth': 6, 'subsample': 0.9862407825133279, 'colsample_bytree': 0.5857635419003775, 'min_child_weight': 8, 'gamma': 0.18152204465888777, 'lambda': 0.14442660556652942, 'alpha': 2.459443414279423}. Best is trial 5 with value: 0.5250283406873293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done.\n",
      "   -> Trial 5 ì™„ë£Œ! Score: 0.5250 (ì†Œìš”ì‹œê°„: 83.0ì´ˆ)\n",
      "\n",
      "ğŸš€ [Trial 6] ì‹œì‘! (ë°ì´í„° ìƒ˜í”Œë§ ì¤‘...)\n",
      "   Current Fold: 1/3... âœ… Done.\n",
      "   Current Fold: 2/3... âœ… Done.\n",
      "   Current Fold: 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-06 11:44:04,201] Trial 6 finished with value: 0.4496236003380485 and parameters: {'eta': 0.025449585936678357, 'max_depth': 7, 'subsample': 0.885600559144206, 'colsample_bytree': 0.7935995634949332, 'min_child_weight': 10, 'gamma': 4.1061812343875195, 'lambda': 26.36749429784603, 'alpha': 4.7535822372237435}. Best is trial 5 with value: 0.5250283406873293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done.\n",
      "   -> Trial 6 ì™„ë£Œ! Score: 0.4496 (ì†Œìš”ì‹œê°„: 82.4ì´ˆ)\n",
      "\n",
      "ğŸš€ [Trial 7] ì‹œì‘! (ë°ì´í„° ìƒ˜í”Œë§ ì¤‘...)\n",
      "   Current Fold: 1/3... âœ… Done.\n",
      "   Current Fold: 2/3... âœ… Done.\n",
      "   Current Fold: 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-06 11:45:26,740] Trial 7 finished with value: 0.45640460766812635 and parameters: {'eta': 0.03601795613699545, 'max_depth': 6, 'subsample': 0.8313816762401471, 'colsample_bytree': 0.772707973185821, 'min_child_weight': 1, 'gamma': 2.2756038083937424, 'lambda': 6.437797533444982, 'alpha': 9.911483524770201}. Best is trial 5 with value: 0.5250283406873293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done.\n",
      "   -> Trial 7 ì™„ë£Œ! Score: 0.4564 (ì†Œìš”ì‹œê°„: 82.5ì´ˆ)\n",
      "\n",
      "ğŸš€ [Trial 8] ì‹œì‘! (ë°ì´í„° ìƒ˜í”Œë§ ì¤‘...)\n",
      "   Current Fold: 1/3... âœ… Done.\n",
      "   Current Fold: 2/3... âœ… Done.\n",
      "   Current Fold: 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-06 11:46:28,014] Trial 8 finished with value: 0.4573527657478943 and parameters: {'eta': 0.08818330135875674, 'max_depth': 4, 'subsample': 0.7450580699067644, 'colsample_bytree': 0.7066637563333003, 'min_child_weight': 5, 'gamma': 3.8819478066458792, 'lambda': 65.86518804877579, 'alpha': 3.2279784892359995}. Best is trial 5 with value: 0.5250283406873293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done.\n",
      "   -> Trial 8 ì™„ë£Œ! Score: 0.4574 (ì†Œìš”ì‹œê°„: 61.2ì´ˆ)\n",
      "\n",
      "ğŸš€ [Trial 9] ì‹œì‘! (ë°ì´í„° ìƒ˜í”Œë§ ì¤‘...)\n",
      "   Current Fold: 1/3... âœ… Done.\n",
      "   Current Fold: 2/3... âœ… Done.\n",
      "   Current Fold: 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-06 11:47:46,150] Trial 9 finished with value: 0.4549983672339241 and parameters: {'eta': 0.044163157513385815, 'max_depth': 7, 'subsample': 0.7354837808956604, 'colsample_bytree': 0.5166503467939775, 'min_child_weight': 4, 'gamma': 2.2854772263487, 'lambda': 45.772934866955744, 'alpha': 9.996963986647163}. Best is trial 5 with value: 0.5250283406873293.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done.\n",
      "   -> Trial 9 ì™„ë£Œ! Score: 0.4550 (ì†Œìš”ì‹œê°„: 78.1ì´ˆ)\n",
      "\n",
      "ğŸ† ìµœì ì˜ íŒŒë¼ë¯¸í„°: {'eta': 0.0726332393055898, 'max_depth': 6, 'subsample': 0.9862407825133279, 'colsample_bytree': 0.5857635419003775, 'min_child_weight': 8, 'gamma': 0.18152204465888777, 'lambda': 0.14442660556652942, 'alpha': 2.459443414279423}\n",
      "ğŸ† ìµœê³  Macro F1 ì ìˆ˜: 0.5250283406873293\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import xgboost as xgb\n",
    "# import category_encoders as ce\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "# from sklearn.metrics import f1_score\n",
    "# import gc\n",
    "# import time\n",
    "\n",
    "# def objective(trial):\n",
    "#     # --- 1. ì„¤ì • ---\n",
    "#     SAMPLE_FRAC = 0.05  # âš¡ ì†ë„ í™•ì¸ì„ ìœ„í•´ 5%ë¡œ ì¤„ì—¬ì„œ ë¨¼ì € í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”!\n",
    "#     N_FOLDS_TUNING = 3 \n",
    "#     RANDOM_STATE = 42\n",
    "    \n",
    "#     print(f\"\\nğŸš€ [Trial {trial.number}] ì‹œì‘! (ë°ì´í„° ìƒ˜í”Œë§ ì¤‘...)\")\n",
    "#     start_trial = time.time()\n",
    "\n",
    "#     # --- 2. ë°ì´í„° ìƒ˜í”Œë§ ---\n",
    "#     try:\n",
    "#         _, X_sample, _, y_sample = train_test_split(\n",
    "#             X, y_encoded, test_size=SAMPLE_FRAC,\n",
    "#             random_state=RANDOM_STATE + trial.number, stratify=y_encoded\n",
    "#         )\n",
    "#         X_sample = X_sample.reset_index(drop=True)\n",
    "#         y_sample = y_sample.reset_index(drop=True) if hasattr(y_sample, 'reset_index') else y_sample\n",
    "#     except Exception as e:\n",
    "#         print(f\"âŒ Subsampling Error: {e}\")\n",
    "#         return 0.0\n",
    "    \n",
    "#     gc.collect()\n",
    "\n",
    "#     params = {\n",
    "#         'objective': 'multi:softprob',\n",
    "#         'num_class': num_classes,\n",
    "#         'eval_metric': 'mlogloss',\n",
    "#         'eta': trial.suggest_float('eta', 0.01, 0.1, log=True),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 4, 10),\n",
    "#         'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "#         'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "#         'gamma': trial.suggest_float('gamma', 0.0, 5.0),\n",
    "#         'lambda': trial.suggest_float('lambda', 0.1, 100.0, log=True),\n",
    "#         'alpha': trial.suggest_float('alpha', 0.0, 10.0),\n",
    "#         'tree_method': 'hist',\n",
    "#         'device': 'cuda',\n",
    "#         'random_state': RANDOM_STATE,\n",
    "#         'nthread': -1\n",
    "#     }\n",
    "\n",
    "#     oof_preds_proba = np.zeros((len(X_sample), num_classes))\n",
    "#     oof_labels = np.zeros(len(X_sample))\n",
    "#     kf = StratifiedKFold(n_splits=N_FOLDS_TUNING, shuffle=True, random_state=RANDOM_STATE)\n",
    "#     cat_cols = X_sample.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "#     # --- 3. Fold ë°˜ë³µ ---\n",
    "#     for fold, (train_idx, val_idx) in enumerate(kf.split(X_sample, y_sample)):\n",
    "#         print(f\"   Current Fold: {fold+1}/{N_FOLDS_TUNING}...\", end=\" \")\n",
    "        \n",
    "#         X_train_fold, X_val_fold = X_sample.iloc[train_idx].copy(), X_sample.iloc[val_idx].copy()\n",
    "#         y_train_fold, y_val_fold = y_sample[train_idx], y_sample[val_idx]\n",
    "\n",
    "#         # (1) Target Encoding\n",
    "#         if cat_cols:\n",
    "#             try:\n",
    "#                 te = ce.TargetEncoder(cols=cat_cols, handle_missing='value', handle_unknown='value', smoothing=1.0)\n",
    "#                 X_train_fold = te.fit_transform(X_train_fold, y_train_fold)\n",
    "#                 X_val_fold = te.transform(X_val_fold)\n",
    "#             except Exception as e: print(f\"(TE Skip: {e})\", end=\" \")\n",
    "\n",
    "#         # (2) SMOTE (ì—¬ê¸°ê°€ ì˜¤ë˜ ê±¸ë¦¼)\n",
    "#         try:\n",
    "#             # print(\"SMOTE...\", end=\" \") # ë„ˆë¬´ ì‹œë„ëŸ¬ìš°ë©´ ì£¼ì„ ì²˜ë¦¬\n",
    "#             smote = SMOTE(random_state=RANDOM_STATE + fold + trial.number, k_neighbors=5)\n",
    "#             X_train_resampled, y_train_resampled = smote.fit_resample(X_train_fold, y_train_fold)\n",
    "#         except:\n",
    "#             X_train_resampled, y_train_resampled = X_train_fold, y_train_fold\n",
    "\n",
    "#         X_train_resampled = X_train_resampled.astype(np.float32)\n",
    "#         X_val_fold = X_val_fold.astype(np.float32)\n",
    "\n",
    "#         # (3) XGBoost\n",
    "#         # print(\"Train...\", end=\" \")\n",
    "#         dtrain = xgb.DMatrix(X_train_resampled, label=y_train_resampled)\n",
    "#         dval = xgb.DMatrix(X_val_fold, label=y_val_fold)\n",
    "        \n",
    "#         booster = xgb.train(\n",
    "#             params=params, dtrain=dtrain, num_boost_round=300, # ë¼ìš´ë“œ ìˆ˜ ì¤„ì„ (ì†ë„ í–¥ìƒ)\n",
    "#             evals=[(dval, 'eval')], early_stopping_rounds=30,\n",
    "#             verbose_eval=False\n",
    "#         )\n",
    "\n",
    "#         val_preds = booster.predict(dval, iteration_range=(0, booster.best_iteration))\n",
    "#         oof_preds_proba[val_idx] = val_preds\n",
    "#         oof_labels[val_idx] = y_val_fold\n",
    "        \n",
    "#         print(\"âœ… Done.\") # Fold ì™„ë£Œ í‘œì‹œ\n",
    "#         del X_train_fold, X_val_fold, dtrain, dval, booster; gc.collect()\n",
    "\n",
    "#     # --- 4. ê²°ê³¼ ì¶œë ¥ ---\n",
    "#     final_preds = np.argmax(oof_preds_proba, axis=1)\n",
    "#     macro_f1 = f1_score(oof_labels, final_preds, average='macro', zero_division=0)\n",
    "    \n",
    "#     elapsed = time.time() - start_trial\n",
    "#     print(f\"   -> Trial {trial.number} ì™„ë£Œ! Score: {macro_f1:.4f} (ì†Œìš”ì‹œê°„: {elapsed:.1f}ì´ˆ)\")\n",
    "    \n",
    "#     return macro_f1\n",
    "\n",
    "# # ğŸ† ì‹¤í–‰\n",
    "# print(\"ğŸ”„ Optuna ìµœì í™” ì‹œì‘ (ë¡œê·¸ ì¶œë ¥ ëª¨ë“œ)...\")\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective, n_trials=10) # ì¼ë‹¨ 10íšŒë§Œ\n",
    "\n",
    "# print(\"\\nğŸ† ìµœì ì˜ íŒŒë¼ë¯¸í„°:\", study.best_params)\n",
    "# print(\"ğŸ† ìµœê³  Macro F1 ì ìˆ˜:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415b33c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ğŸ† [Step 2] ìµœì¢… í•™ìŠµ ë° ì œì¶œ íŒŒì¼ ìƒì„± (ìë™ ì—°ë™)\n",
    "# =============================================================================\n",
    "\n",
    "# 1. ìµœì  íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸° (ì†ìœ¼ë¡œ ì…ë ¥í•  í•„ìš” X)\n",
    "print(\"\\nğŸ”„ [ì‹œìŠ¤í…œ] ìµœì  íŒŒë¼ë¯¸í„° ë¡œë“œ ì¤‘...\")\n",
    "\n",
    "try:\n",
    "    # ë°©ê¸ˆ Optunaê°€ ì°¾ì€ ìµœê³ ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    best_params = study.best_params\n",
    "    print(f\"   âœ… Optuna ìµœì ê°’ ë°œê²¬! (eta={best_params.get('eta', 'N/A'):.4f}, depth={best_params.get('max_depth', 'N/A')})\")\n",
    "    \n",
    "    # XGBoost í•„ìˆ˜ ê³ ì • íŒŒë¼ë¯¸í„° ì¶”ê°€\n",
    "    best_params.update({\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': num_classes,\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'tree_method': 'hist',\n",
    "        'device': 'cuda',\n",
    "        'nthread': -1,\n",
    "        'random_state': 42\n",
    "    })\n",
    "    \n",
    "except NameError:\n",
    "    # ë§Œì•½ Optunaë¥¼ ì•ˆ ëŒë¦¬ê³  ë°”ë¡œ ì´ ì½”ë“œë¥¼ ì‹¤í–‰í–ˆì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ 'ë¹„ìƒìš©' ê¸°ë³¸ê°’\n",
    "    print(\"   âš ï¸ Optuna ì‹¤í–‰ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.\")\n",
    "    best_params = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': num_classes,\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'eta': 0.05, \n",
    "        'max_depth': 8,\n",
    "        'tree_method': 'hist',\n",
    "        'device': 'cuda'\n",
    "    }\n",
    "\n",
    "# 2. ìµœì¢… í•™ìŠµ ì‹¤í–‰ ì—¬ë¶€ ê²°ì •\n",
    "# MODEê°€ 'PARAM_TUNING'ì¼ ë•Œë§Œ ìë™ìœ¼ë¡œ 100% í•™ìŠµê¹Œì§€ ì´ì–´ê°€ê²Œ í•˜ê±°ë‚˜,\n",
    "# ì•„ë‹ˆë©´ ë¬´ì¡°ê±´ ì‹¤í–‰í•˜ê²Œ í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„  ì§ˆë¬¸í•˜ì‹  ëŒ€ë¡œ 'ì—°ê²°'í•´ë“œë¦½ë‹ˆë‹¤.\n",
    "\n",
    "if MODE == 'PARAM_TUNING':\n",
    "    print(\"\\nğŸš€ [32GB Full Power] ì „ì²´ ë°ì´í„°(100%)ë¡œ ìµœì¢… í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤!\")\n",
    "    \n",
    "    # (1) ë°ì´í„° ì„¤ì • (ì „ì²´ ë°ì´í„° X, y_encoded ì‚¬ìš©)\n",
    "    N_FOLDS_FINAL = 5\n",
    "    kf = StratifiedKFold(n_splits=N_FOLDS_FINAL, shuffle=True, random_state=42)\n",
    "    \n",
    "    final_test_preds = np.zeros((len(X_test), num_classes))\n",
    "    oof_preds = np.zeros((len(X), num_classes))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # (2) 5-Fold í•™ìŠµ ë£¨í”„\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X, y_encoded)):\n",
    "        print(f\"\\n   [Fold {fold+1}/{N_FOLDS_FINAL}] ì§„í–‰ ì¤‘...\", end=\" \")\n",
    "        \n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "        \n",
    "        # Target Encoding\n",
    "        cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        if cat_cols:\n",
    "            te = ce.TargetEncoder(cols=cat_cols)\n",
    "            X_train = te.fit_transform(X_train, y_train)\n",
    "            X_val = te.transform(X_val)\n",
    "            X_test_fold = te.transform(X_test.copy())\n",
    "        else:\n",
    "            X_test_fold = X_test.copy()\n",
    "\n",
    "        # SMOTE (ë©”ëª¨ë¦¬ í„°ì§ˆ ìˆ˜ ìˆìœ¼ë‹ˆ ì¡°ì‹¬)\n",
    "        try:\n",
    "            smote = SMOTE(random_state=42+fold, k_neighbors=5)\n",
    "            X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "        except: pass # ë©”ëª¨ë¦¬ ë¶€ì¡±í•˜ë©´ íŒ¨ìŠ¤\n",
    "        \n",
    "        # XGBoost Train\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        dval = xgb.DMatrix(X_val, label=y_val)\n",
    "        dtest = xgb.DMatrix(X_test_fold)\n",
    "        \n",
    "        model = xgb.train(\n",
    "            params=best_params, # âœ… ì•„ê¹Œ ì°¾ì€ ìµœì ê°’ ìë™ ì ìš©\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=2000, # ìµœì¢…ì´ë‹ˆê¹Œ ë„‰ë„‰í•˜ê²Œ\n",
    "            evals=[(dval, 'eval')],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        \n",
    "        # ì˜ˆì¸¡\n",
    "        oof_preds[val_idx] = model.predict(dval, iteration_range=(0, model.best_iteration))\n",
    "        final_test_preds += model.predict(dtest, iteration_range=(0, model.best_iteration)) / N_FOLDS_FINAL\n",
    "        \n",
    "        # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "        del X_train, X_val, dtrain, dval, dtest, model; gc.collect()\n",
    "        print(\"ì™„ë£Œ.\")\n",
    "\n",
    "    # (3) ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "    print(f\"\\nâœ… ìµœì¢… í•™ìŠµ ì™„ë£Œ! (ì†Œìš”ì‹œê°„: {(time.time() - start_time)/60:.1f}ë¶„)\")\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'ID': X_test.index if 'ID' not in X_test.columns else X_test['ID'],\n",
    "        'Segment': np.argmax(final_test_preds, axis=1)\n",
    "    })\n",
    "    submission.to_csv('final_submission_auto.csv', index=False)\n",
    "    print(\"ğŸ‰ ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: final_submission_auto.csv\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nâœ‹ [ì‹¤í—˜ ì¢…ë£Œ] íŒŒìƒë³€ìˆ˜ í…ŒìŠ¤íŠ¸ ëª¨ë“œì´ë¯€ë¡œ ìµœì¢… í•™ìŠµì€ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "    print(\"   -> ìµœì¢… í•™ìŠµì„ í•˜ë ¤ë©´ ë§¨ ìœ„ MODEë¥¼ 'PARAM_TUNING'ìœ¼ë¡œ ë°”ê¿”ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c5650a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ† Optuna ìµœì  íŒŒë¼ë¯¸í„° ë¡œë“œ ì™„ë£Œ.\n",
      "\n",
      "ğŸš€ [32GB Mode] ìµœì¢… í•™ìŠµ ì‹œì‘ (SMOTE ON)...\n",
      "\n",
      "ğŸ”„ [Fold 1/5] ë°ì´í„° ë¶„í•  ì¤‘... Target Encoding ì™„ë£Œ... âš ï¸ SMOTE ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ê±´ë„ˆëœ€(Unable to allocate 5.00 GiB for an array with shape (1536865, 437) and data type float64)... í•™ìŠµ ì‹œì‘...\n",
      "   -> Fold 1 ì™„ë£Œ. Score: 0.68805 (ì†Œìš”: 42.1ë¶„)\n",
      "\n",
      "ğŸ”„ [Fold 2/5] ë°ì´í„° ë¶„í•  ì¤‘... Target Encoding ì™„ë£Œ... âš ï¸ SMOTE ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ê±´ë„ˆëœ€(Unable to allocate 5.01 GiB for an array with shape (1537527, 437) and data type float64)... í•™ìŠµ ì‹œì‘...\n",
      "   -> Fold 2 ì™„ë£Œ. Score: 0.71978 (ì†Œìš”: 19.7ë¶„)\n",
      "\n",
      "ğŸ”„ [Fold 3/5] ë°ì´í„° ë¶„í•  ì¤‘... Target Encoding ì™„ë£Œ... âš ï¸ SMOTE ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ê±´ë„ˆëœ€(Unable to allocate 25.0 GiB for an array with shape (7688205, 437) and data type float64)... í•™ìŠµ ì‹œì‘...\n",
      "   -> Fold 3 ì™„ë£Œ. Score: 0.68229 (ì†Œìš”: 23.8ë¶„)\n",
      "\n",
      "ğŸ”„ [Fold 4/5] ë°ì´í„° ë¶„í•  ì¤‘... Target Encoding ì™„ë£Œ... âš ï¸ SMOTE ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ê±´ë„ˆëœ€(Unable to allocate 25.0 GiB for an array with shape (7688205, 437) and data type float64)... í•™ìŠµ ì‹œì‘...\n",
      "   -> Fold 4 ì™„ë£Œ. Score: 0.67705 (ì†Œìš”: 23.9ë¶„)\n",
      "\n",
      "ğŸ”„ [Fold 5/5] ë°ì´í„° ë¶„í•  ì¤‘... Target Encoding ì™„ë£Œ... âš ï¸ SMOTE ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ê±´ë„ˆëœ€(Unable to allocate 25.0 GiB for an array with shape (7688210, 437) and data type float64)... í•™ìŠµ ì‹œì‘...\n",
      "   -> Fold 5 ì™„ë£Œ. Score: 0.69646 (ì†Œìš”: 23.1ë¶„)\n",
      "\n",
      "âœ… ì „ì²´ í•™ìŠµ ì™„ë£Œ! (ì´ ì†Œìš”: 132.8ë¶„)\n",
      "ğŸ† Final OOF Macro F1 Score: 0.69381\n",
      "ğŸ‰ ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: submission_xgb_smote_32gb.csv\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import xgboost as xgb\n",
    "# import category_encoders as ce\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import f1_score\n",
    "# import gc\n",
    "# import time\n",
    "\n",
    "# # ====================================================\n",
    "# # 1. íŒŒë¼ë¯¸í„° ë° ì„¤ì •\n",
    "# # ====================================================\n",
    "# try:\n",
    "#     best_params = study.best_params\n",
    "#     print(f\"ğŸ† Optuna ìµœì  íŒŒë¼ë¯¸í„° ë¡œë“œ ì™„ë£Œ.\")\n",
    "# except:\n",
    "#     print(\"âš ï¸ Optuna ê²°ê³¼ê°€ ì—†ì–´ ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "#     best_params = {\n",
    "#         # 'eta': 0.05, 'max_depth': 8, 'subsample': 0.8,\n",
    "#         'colsample_bytree': 0.8, 'min_child_weight': 3,\n",
    "#         'gamma': 1, 'lambda': 10, 'alpha': 1\n",
    "#     }\n",
    "\n",
    "# best_params.update({\n",
    "#     'objective': 'multi:softprob',\n",
    "#     'num_class': num_classes,\n",
    "#     'eval_metric': 'mlogloss',\n",
    "#     'tree_method': 'hist',\n",
    "#     'device': 'cuda',\n",
    "#     'nthread': -1,\n",
    "#     'random_state': 42\n",
    "# })\n",
    "\n",
    "# # ====================================================\n",
    "# # 2. 5-Fold ìµœì¢… í•™ìŠµ (Safety SMOTE ì ìš©)\n",
    "# # ====================================================\n",
    "# N_FOLDS = 5\n",
    "# kf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# final_test_preds = np.zeros((len(X_test), num_classes))\n",
    "# oof_preds = np.zeros((len(X_final), num_classes))\n",
    "\n",
    "# print(f\"\\nğŸš€ [32GB Mode] ìµœì¢… í•™ìŠµ ì‹œì‘ (SMOTE ON)...\")\n",
    "# start_time = time.time()\n",
    "\n",
    "# cat_cols = X_final.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# for fold, (train_idx, val_idx) in enumerate(kf.split(X_final, y_encoded)):\n",
    "#     fold_start = time.time()\n",
    "#     print(f\"\\nğŸ”„ [Fold {fold+1}/{N_FOLDS}] ë°ì´í„° ë¶„í•  ì¤‘...\", end=\" \")\n",
    "    \n",
    "#     X_train, X_val = X_final.iloc[train_idx].copy(), X_final.iloc[val_idx].copy()\n",
    "#     y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "    \n",
    "#     # (1) Target Encoding\n",
    "#     if cat_cols:\n",
    "#         te = ce.TargetEncoder(cols=cat_cols, handle_missing='value', handle_unknown='value', smoothing=1.0)\n",
    "#         X_train = te.fit_transform(X_train, y_train)\n",
    "#         X_val = te.transform(X_val)\n",
    "#         X_test_fold = te.transform(X_test.copy()) # Testì…‹ì€ ë³µì‚¬í•´ì„œ ë³€í™˜\n",
    "#     else:\n",
    "#         X_test_fold = X_test.copy()\n",
    "        \n",
    "#     print(\"Target Encoding ì™„ë£Œ...\", end=\" \")\n",
    "\n",
    "#     # (2) SMOTE (ë©”ëª¨ë¦¬ ì•ˆì „ì¥ì¹˜ ì¶”ê°€)\n",
    "#     try:\n",
    "#         # print(\"SMOTE ì ìš© ì‹œë„...\", end=\" \")\n",
    "#         smote = SMOTE(random_state=42 + fold, k_neighbors=5)\n",
    "#         # SMOTEëŠ” ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ì“°ë¯€ë¡œ try-exceptë¡œ ê°ìŒˆ\n",
    "#         X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "#         print(f\"SMOTE ì„±ê³µ(Train: {len(X_train)}í–‰)...\", end=\" \")\n",
    "#     except Exception as e:\n",
    "#         print(f\"âš ï¸ SMOTE ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ê±´ë„ˆëœ€({e})...\", end=\" \")\n",
    "#         # ì‹¤íŒ¨í•˜ë©´ ì›ë³¸ ê·¸ëŒ€ë¡œ ì§„í–‰ (ë©ˆì¶”ì§€ ì•ŠìŒ)\n",
    "\n",
    "#     # (3) ìˆ˜ì¹˜í˜• ë³€í™˜ (ë©”ëª¨ë¦¬ ë‹¤ì´ì–´íŠ¸)\n",
    "#     X_train = X_train.apply(pd.to_numeric, errors='coerce').fillna(0).astype(np.float32)\n",
    "#     X_val = X_val.apply(pd.to_numeric, errors='coerce').fillna(0).astype(np.float32)\n",
    "#     X_test_fold = X_test_fold.apply(pd.to_numeric, errors='coerce').fillna(0).astype(np.float32)\n",
    "    \n",
    "#     # (4) XGBoost í•™ìŠµ\n",
    "#     dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "#     dval = xgb.DMatrix(X_val, label=y_val)\n",
    "#     dtest = xgb.DMatrix(X_test_fold)\n",
    "    \n",
    "#     print(\"í•™ìŠµ ì‹œì‘...\")\n",
    "#     model = xgb.train(\n",
    "#         params=best_params,\n",
    "#         dtrain=dtrain,\n",
    "#         num_boost_round=1500, # SMOTE ë°ì´í„°ëŠ” í•™ìŠµì´ ë” í•„ìš”í•  ìˆ˜ ìˆì–´ ë¼ìš´ë“œ ì¦ê°€\n",
    "#         evals=[(dval, 'eval')],\n",
    "#         early_stopping_rounds=50,\n",
    "#         verbose_eval=False # ë¡œê·¸ ë„ˆë¬´ ê¸¸ë©´ ë”\n",
    "#     )\n",
    "    \n",
    "#     # (5) ì˜ˆì¸¡ ë° ì •ë¦¬\n",
    "#     oof_preds[val_idx] = model.predict(dval, iteration_range=(0, model.best_iteration))\n",
    "#     final_test_preds += model.predict(dtest, iteration_range=(0, model.best_iteration)) / N_FOLDS\n",
    "    \n",
    "#     # í˜„ì¬ Fold ì ìˆ˜ í™•ì¸\n",
    "#     fold_pred_labels = np.argmax(oof_preds[val_idx], axis=1)\n",
    "#     fold_score = f1_score(y_val, fold_pred_labels, average='macro')\n",
    "#     print(f\"   -> Fold {fold+1} ì™„ë£Œ. Score: {fold_score:.5f} (ì†Œìš”: {(time.time()-fold_start)/60:.1f}ë¶„)\")\n",
    "    \n",
    "#     # ë©”ëª¨ë¦¬ ì¦‰ì‹œ í•´ì œ (ê°€ì¥ ì¤‘ìš”)\n",
    "#     del X_train, X_val, y_train, y_val, dtrain, dval, dtest, model, X_test_fold\n",
    "#     gc.collect()\n",
    "\n",
    "# # ====================================================\n",
    "# # 3. ê²°ê³¼ ì €ì¥\n",
    "# # ====================================================\n",
    "# print(f\"\\nâœ… ì „ì²´ í•™ìŠµ ì™„ë£Œ! (ì´ ì†Œìš”: {(time.time() - start_time)/60:.1f}ë¶„)\")\n",
    "\n",
    "# # OOF ì ìˆ˜\n",
    "# oof_pred_labels = np.argmax(oof_preds, axis=1)\n",
    "# final_score = f1_score(y_encoded, oof_pred_labels, average='macro')\n",
    "# print(f\"ğŸ† Final OOF Macro F1 Score: {final_score:.5f}\")\n",
    "\n",
    "# # ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "# test_pred_labels = np.argmax(final_test_preds, axis=1)\n",
    "# submission_id = X_test.index if 'ID' not in X_test.columns else X_test['ID']\n",
    "\n",
    "# submission = pd.DataFrame({\n",
    "#     'ID': submission_id,\n",
    "#     'Segment': test_pred_labels\n",
    "# })\n",
    "\n",
    "# submission.to_csv('submission_xgb_smote_32gb.csv', index=False)\n",
    "# print(\"ğŸ‰ ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: submission_xgb_smote_32gb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ddf0790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.\n",
      "   - ìƒ˜í”Œ í–‰ ìˆ˜: 100000\n",
      "   - ì˜ˆì¸¡ í–‰ ìˆ˜: 600000\n",
      "\n",
      "ğŸ‰ ìµœì¢… ì œì¶œ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "ğŸ“ ì €ì¥ ê²½ë¡œ: C:\\Users\\CY2\\github\\DataScience\\final_submission_recovered.csv\n",
      "\n",
      "[ì œì¶œ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°]\n",
      "           ID Segment\n",
      "0  TEST_00000       E\n",
      "1  TEST_00001       E\n",
      "2  TEST_00002       D\n",
      "3  TEST_00003       E\n",
      "4  TEST_00004       E\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. íŒŒì¼ ê²½ë¡œ ì„¤ì • (ì‚¬ìš©ìë‹˜ì˜ PC í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •)\n",
    "sample_path = r'C:\\Users\\CY2\\github\\DataScience\\Credit Card\\sample_submission.csv'\n",
    "pred_file_path = r'C:\\Users\\CY2\\github\\DataScience\\submission_xgb_smote_32gb.csv'\n",
    "\n",
    "try:\n",
    "    # ë°ì´í„° ë¡œë“œ\n",
    "    sample_sub = pd.read_csv(sample_path)\n",
    "    user_pred = pd.read_csv(pred_file_path)\n",
    "\n",
    "    print(f\"âœ… íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.\")\n",
    "    print(f\"   - ìƒ˜í”Œ í–‰ ìˆ˜: {len(sample_sub)}\")\n",
    "    print(f\"   - ì˜ˆì¸¡ í–‰ ìˆ˜: {len(user_pred)}\")\n",
    "\n",
    "    # 2. ìˆ«ì ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ë¬¸ìë¡œ ë§¤í•‘ (0->A, 1->B, 2->C, 3->D, 4->E)\n",
    "    # ë§Œì•½ ê¸°ì¡´ì— ì‚¬ìš©í–ˆë˜ LabelEncoder ìˆœì„œê°€ ë‹¤ë¥´ë‹¤ë©´ ì´ ë¶€ë¶„ì„ ìˆ˜ì •í•˜ì„¸ìš”.\n",
    "    mapping = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E'}\n",
    "    \n",
    "    # 3. ë°ì´í„° ë§¤ì¹­ ë° ë³€í™˜\n",
    "    # ìƒ˜í”Œ íŒŒì¼ì˜ í–‰ ìˆ˜(100,000)ë§Œí¼ ì˜ˆì¸¡ ë°ì´í„°ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    target_preds = user_pred.iloc[:len(sample_sub)].copy()\n",
    "    \n",
    "    # ë§¤í•‘ ì ìš©\n",
    "    sample_sub['Segment'] = target_preds['Segment'].map(mapping)\n",
    "\n",
    "    # 4. ê²°ì¸¡ì¹˜ í™•ì¸ ë° ì²˜ë¦¬ (ë§Œì•½ ë§¤í•‘ë˜ì§€ ì•Šì€ ê°’ì´ ìˆë‹¤ë©´ 'A'ë¡œ ê¸°ë³¸ê°’ ì²˜ë¦¬)\n",
    "    if sample_sub['Segment'].isnull().any():\n",
    "        print(\"âš ï¸ ë§¤í•‘ë˜ì§€ ì•Šì€ ê°’ì´ ìˆì–´ ê¸°ë³¸ê°’ 'A'ë¡œ ì±„ì›ë‹ˆë‹¤.\")\n",
    "        sample_sub['Segment'] = sample_sub['Segment'].fillna('A')\n",
    "\n",
    "    # 5. ìµœì¢… ì €ì¥\n",
    "    save_path = r'C:\\Users\\CY2\\github\\DataScience\\final_submission_recovered.csv'\n",
    "    sample_sub.to_csv(save_path, index=False)\n",
    "\n",
    "    print(f\"\\nğŸ‰ ìµœì¢… ì œì¶œ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    print(f\"ğŸ“ ì €ì¥ ê²½ë¡œ: {save_path}\")\n",
    "    print(\"\\n[ì œì¶œ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°]\")\n",
    "    print(sample_sub.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ ì—ëŸ¬: ì§€ì •ëœ ê²½ë¡œì—ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
