프로젝트 발표 대본: "데이터의 산을 넘어, 모델의 숲으로"
제1발표자: 서론 및 프로젝트 개요 (5분)

주제: 우리가 마주한 데이터와 도전 과제

인사 및 소개: "안녕하세요, 신용카드 등급 판별 머신러닝 프로젝트 발표를 맡게 된 [이름]입니다. 저희 팀은 방대한 금융 데이터를 활용해 신용 등급을 예측하는 모델을 구축했습니다."

데이터의 특성: "이번 프로젝트의 핵심은 '규모'였습니다. 회원정보부터 마케팅, 성과 정보까지 총 8개 카테고리의 데이터를 6개월 치나 다루어야 했습니다. 컬럼 수가 워낙 많고 데이터 양이 거대해서 시작부터 '메모리 부족'이라는 큰 벽에 부딪혔습니다."

초기 문제 인식: "단순히 데이터를 합치는 것만으로도 컴퓨터가 멈추는 상황이었습니다. 저희는 이 문제를 해결하기 위해 '데이터 효율화'와 '모듈화'라는 두 가지 전략을 세웠습니다."

함수 제작의 필요성: "반복되는 작업을 줄이기 위해 make_df와 같은 자동화 함수를 제작했습니다. 파일 경로 설정에서의 사소한 실수(슬래시 누락 등)를 바로잡으며, 데이터를 안전하게 불러오는 뼈대를 구축하는 데 집중한 0일 차와 1일 차의 과정을 소개하며 발표를 시작합니다."
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
제2발표자: 본론 1 - 메모리와의 전쟁, 최적화 전략 (5분)
주제: 한정된 자원으로 대용량 데이터 요리하기

메모리 최적화 기법: "저희가 가장 먼저 해결해야 했던 문제는 메모리 관리였습니다. 첫 번째 전략은 데이터 다운그레이드였습니다. 기본 64비트로 불러와지는 숫자 데이터를 32비트나 16비트로 낮추어 메모리 사용량을 획기적으로 줄였습니다."

가상 메모리와 하드웨어 활용: "소프트웨어적 방법 외에도 SSD의 빈 공간을 가상 메모리로 할당하거나, CPU의 한계를 넘기 위해 CUDA 기반의 GPU 가속을 검토하는 등 하드웨어 자원을 극대화하는 시도를 병행했습니다."

협업 중 발생한 이슈: "이 과정에서 흥미로운 삽질(?)도 있었습니다. 팀원 간 Pandas 버전 차이로 인해 특정 환경에서만 데이터 병합이 안 되는 문제가 발생했죠. 버전을 통일하며 환경 동기화의 중요성을 뼈저리게 느꼈습니다."

주의사항 공유: "다만, 다운그레이드된 데이터가 머신러닝 학습 시 다시 64비트로 변환되며 메모리가 폭증할 수 있다는 점을 인지하고, 이를 관리하는 로직을 설계하는 데 공을 들였습니다."
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
제3발표자: 본론 2 - 피처 엔지니어링과 도메인의 한계 (5분)
주제: 수많은 컬럼 속에서 의미 있는 보석 찾기

컬럼 선정의 어려움: "데이터가 너무 많다는 것은 곧 노이즈가 많다는 뜻이기도 합니다. 저희는 상관관계 분석을 통해 일정 기준 이상의 관계를 가진 컬럼만 추출했습니다. 하지만 금융 데이터 특성상 전문 용어가 많아 도메인 지식의 한계에 부딪혔습니다."

AI와의 협업: "이름만 봐서는 알기 힘든 금융 변수들을 분석하기 위해 AI의 도움을 받아 인사이트를 얻었습니다. AI가 추천한 컬럼들을 맹신하지 않고, 팀원들과 함께 EDA(탐색적 데이터 분석)를 진행하며 유의미한 변수들을 카테고리별로 재분류했습니다."

유사 데이터 병합 함수: "특히 유사한 관계를 지닌 컬럼들을 한 번에 처리하기 위해 find_R 같은 함수를 만들어 사용했습니다. 특정 키워드가 포함된 컬럼들을 묶어 관리함으로써, 수백 개의 컬럼을 효율적으로 통제할 수 있었습니다."

시각화 자동화: "수많은 컬럼을 일일이 그래프로 그리는 '무식한' 방식에서 벗어나, 함수를 통해 시각화를 자동화하며 업무 효율을 높였습니다."
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
제4발표자: 결론 - 모델링과 프로젝트 회고 (5분)
주제: CatBoost 선택 이유와 우리가 얻은 교훈

모델 선택 (CatBoost): "저희가 최종적으로 주목한 모델은 CatBoost입니다. 금융 데이터처럼 카테고리형 변수가 많고 클래스 불균형이 심한 데이터에 강점이 있기 때문입니다. 특히 상관관계가 낮아 보여도 분류 기준에 적합하면 높은 참고율을 보이는 CatBoost의 특성이 저희 데이터셋과 잘 맞았습니다."

시행착오와 복구: "프로젝트 막바지, 전처리 과정에서 컬럼 제거 순서가 꼬여 코드가 작동하지 않거나, 깃허브 충돌로 인해 소중한 코드가 날아가는 아찔한 순간도 있었습니다. 하지만 이를 통해 '저장의 생활화'와 '기록의 중요성'을 다시금 배웠습니다."

프로젝트 성과 및 마무리: "매일 텍스트 파일로 작업 내역을 기록하며 팀원들과 코드 리뷰를 진행한 덕분에, 결국 견고한 데이터 파이프라인과 모델 뼈대를 완성할 수 있었습니다."

마지막 한마디: "데이터 분석은 단순히 기술의 문제가 아니라, 환경과 도메인, 그리고 팀워크의 조화라는 것을 깨달은 프로젝트였습니다. 이상으로 발표를 마칩니다. 감사합니다."
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------